{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f203bf6",
   "metadata": {},
   "source": [
    "Importaciones y configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f487c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nic_s\\anaconda3\\envs\\deepgpu\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5a2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === Configuraci√≥n adaptativa (CUDA/CPU) ===\n",
    "TRAIN_DIR = \"./tav_clean/training\"\n",
    "VALIDATION_DIR = \"./tav_clean/validacion\"\n",
    "CLIP_DURATION = 2.56  # segundos\n",
    "STRIDE = 1.0  # segundos\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4\n",
    "EARLY_STOPPING_PATIENCE = 3\n",
    "OUTPUT_MODEL = \"i3d_finetuned_violencia_robo_normal.pth\"\n",
    "METRICS_FILE = \"training_metrics.xlsx\"\n",
    "PRETRAINED_MODEL = \"I3D_8x8_R50_pytorchvideo.pyth\"  # Formato PyTorchVideo\n",
    "LABELS = [\"Normal\", \"Robo\", \"Violencia\"]\n",
    "TARGET_SIZE = (224, 224)\n",
    "NUM_FRAMES = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0395e5f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c39c7f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VRAM detectada: 4.3 GB\n",
      "‚ö° Configuraci√≥n optimizada: batch_size=4, num_workers=3\n",
      "üöÄ GPU detectada: NVIDIA GeForce GTX 1650 Ti\n",
      "üíæ VRAM total: 4.3 GB\n",
      "üñ•Ô∏è  Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "def get_hardware_config():\n",
    "    if torch.cuda.is_available():\n",
    "        # Detectar capacidad de VRAM autom√°ticamente\n",
    "        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"üîç VRAM detectada: {gpu_memory_gb:.1f} GB\")\n",
    "        \n",
    "        # Configuraci√≥n solicitada: batch_size=4\n",
    "        batch_size = 4\n",
    "        num_workers = 3  # Un valor razonable para este batch size\n",
    "            \n",
    "        print(f\"‚ö° Configuraci√≥n optimizada: batch_size={batch_size}, num_workers={num_workers}\")\n",
    "        \n",
    "        return {\n",
    "            'batch_size': batch_size,\n",
    "            'num_workers': num_workers,\n",
    "            'pin_memory': True,\n",
    "            'use_mixed_precision': True,\n",
    "            'cuda_device': 0\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'batch_size': 1,  # CPU usa batch size m√°s peque√±o\n",
    "            'num_workers': 0,\n",
    "            'pin_memory': False,\n",
    "            'use_mixed_precision': False,\n",
    "            'cuda_device': None\n",
    "        }\n",
    "\n",
    "# Obtener configuraci√≥n seg√∫n hardware disponible\n",
    "config = get_hardware_config()\n",
    "\n",
    "# Verificar CUDA y configurar device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(f'cuda:{config[\"cuda_device\"]}')\n",
    "    gpu_name = torch.cuda.get_device_name(config[\"cuda_device\"])\n",
    "    gpu_memory = torch.cuda.get_device_properties(config[\"cuda_device\"]).total_memory / 1e9\n",
    "    print(f\"üöÄ GPU detectada: {gpu_name}\")\n",
    "    print(f\"üíæ VRAM total: {gpu_memory:.1f} GB\")\n",
    "    print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "    \n",
    "    # Limpiar cache de GPU\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f\"‚ö†Ô∏è  CUDA no disponible, usando CPU\")\n",
    "    print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "    print(f\"üí° Para usar GPU, ejecuta: setup_cuda.bat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6440970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Dataset con sliding window ===\n",
    "class SlidingWindowVideoDataset(Dataset):\n",
    "    def __init__(self, video_paths, clip_duration, stride, num_frames=64):\n",
    "        self.clips = []\n",
    "        self.clip_duration = clip_duration\n",
    "        self.stride = stride\n",
    "        self.num_frames = num_frames\n",
    "        \n",
    "        # Generar todos los clips con sliding window\n",
    "        for video_path, label in video_paths:\n",
    "            clips_from_video = self._generate_clips(video_path, label)\n",
    "            self.clips.extend(clips_from_video)\n",
    "        \n",
    "        print(f\"üìä Total de clips generados: {len(self.clips)}\")\n",
    "    \n",
    "    def _generate_clips(self, video_path, label):\n",
    "        \"\"\"Genera clips usando sliding window para un video\"\"\"\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            cap.release()\n",
    "            \n",
    "            if fps <= 0:\n",
    "                return []\n",
    "            \n",
    "            video_duration = total_frames / fps\n",
    "            clips = []\n",
    "            \n",
    "            start_time = 0.0\n",
    "            while start_time + self.clip_duration <= video_duration:\n",
    "                start_frame = int(start_time * fps)\n",
    "                end_frame = int((start_time + self.clip_duration) * fps)\n",
    "                \n",
    "                clips.append({\n",
    "                    'video_path': video_path,\n",
    "                    'label': label,\n",
    "                    'start_frame': start_frame,\n",
    "                    'end_frame': end_frame,\n",
    "                    'fps': fps\n",
    "                })\n",
    "                \n",
    "                start_time += self.stride\n",
    "            \n",
    "            return clips\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error procesando {video_path}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.clips)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        clip_info = self.clips[idx]\n",
    "        \n",
    "        # Cargar frames del clip\n",
    "        frames = self._load_video_clip(\n",
    "            clip_info['video_path'],\n",
    "            clip_info['start_frame'],\n",
    "            clip_info['end_frame']\n",
    "        )\n",
    "        \n",
    "        # Convertir a tensor y aplicar transformaciones\n",
    "        video_tensor = self._preprocess_frames(frames)\n",
    "        \n",
    "        return {\n",
    "            'video': video_tensor,\n",
    "            'label': torch.tensor(clip_info['label'], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    def _load_video_clip(self, video_path, start_frame, end_frame):\n",
    "        \"\"\"Carga frames espec√≠ficos de un video\"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        \n",
    "        # Calcular √≠ndices de frames a extraer\n",
    "        total_clip_frames = end_frame - start_frame\n",
    "        if total_clip_frames <= 0:\n",
    "            cap.release()\n",
    "            return [np.zeros((*TARGET_SIZE, 3), dtype=np.uint8)] * self.num_frames\n",
    "        \n",
    "        # Submuestreo uniforme para obtener NUM_FRAMES\n",
    "        frame_indices = np.linspace(start_frame, end_frame-1, self.num_frames, dtype=int)\n",
    "        \n",
    "        for frame_idx in frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if ret:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = cv2.resize(frame, TARGET_SIZE)\n",
    "                frames.append(frame)\n",
    "            else:\n",
    "                # Usar √∫ltimo frame v√°lido si hay error\n",
    "                if frames:\n",
    "                    frames.append(frames[-1])\n",
    "                else:\n",
    "                    frames.append(np.zeros((*TARGET_SIZE, 3), dtype=np.uint8))\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        # Asegurar que tenemos exactamente NUM_FRAMES\n",
    "        while len(frames) < self.num_frames:\n",
    "            frames.append(frames[-1] if frames else np.zeros((*TARGET_SIZE, 3), dtype=np.uint8))\n",
    "        \n",
    "        return frames[:self.num_frames]\n",
    "    \n",
    "    def _preprocess_frames(self, frames):\n",
    "        \"\"\"Convierte frames a tensor y aplica transformaciones\"\"\"\n",
    "        # Convertir a tensor [T, H, W, C]\n",
    "        video_tensor = torch.from_numpy(np.array(frames)).float()\n",
    "        \n",
    "        # Permutar a [C, T, H, W]\n",
    "        video_tensor = video_tensor.permute(3, 0, 1, 2)\n",
    "        \n",
    "        # Normalizar a [0,1]\n",
    "        video_tensor = video_tensor / 255.0\n",
    "        \n",
    "        # Normalizaci√≥n est√°ndar\n",
    "        mean = torch.tensor([0.45, 0.45, 0.45]).view(3, 1, 1, 1)\n",
    "        std = torch.tensor([0.225, 0.225, 0.225]).view(3, 1, 1, 1)\n",
    "        video_tensor = (video_tensor - mean) / std\n",
    "        \n",
    "        return video_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f975a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Funciones de utilidad ===\n",
    "def recolectar_videos(base_dir):\n",
    "    \"\"\"Recolecta todas las rutas de videos con sus etiquetas de forma recursiva\"\"\"\n",
    "    video_paths = []\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(LABELS)}\n",
    "    \n",
    "    for label in LABELS:\n",
    "        label_dir = Path(base_dir) / label\n",
    "        if not label_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è Directorio no encontrado: {label_dir}\")\n",
    "            continue\n",
    "        \n",
    "        # B√∫squeda recursiva de videos .mp4\n",
    "        for video_file in label_dir.glob(\"**/*.mp4\"):\n",
    "            video_paths.append((str(video_file), label_to_idx[label]))\n",
    "    \n",
    "    return video_paths\n",
    "\n",
    "def contar_videos_por_etiqueta(video_paths):\n",
    "    \"\"\"Cuenta videos por cada etiqueta\"\"\"\n",
    "    conteo = defaultdict(int)\n",
    "    for _, label_idx in video_paths:\n",
    "        label_name = LABELS[label_idx]\n",
    "        conteo[label_name] += 1\n",
    "    \n",
    "    print(\"\\nüìä [Resumen de videos por clase]\")\n",
    "    for label, count in conteo.items():\n",
    "        print(f\"   {label}: {count} videos\")\n",
    "    print()\n",
    "\n",
    "def estimar_clips_totales(video_paths):\n",
    "    \"\"\"Estima el n√∫mero total de clips que se generar√°n\"\"\"\n",
    "    total_clips = 0\n",
    "    clips_por_clase = defaultdict(int)\n",
    "    \n",
    "    for video_path, label_idx in video_paths:\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            cap.release()\n",
    "            \n",
    "            if fps > 0:\n",
    "                video_duration = total_frames / fps\n",
    "                num_clips = max(0, int((video_duration - CLIP_DURATION) / STRIDE) + 1)\n",
    "                total_clips += num_clips\n",
    "                clips_por_clase[LABELS[label_idx]] += num_clips\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error estimando clips para {video_path}: {e}\")\n",
    "    \n",
    "    print(\"üìä [Estimaci√≥n de clips por sliding window]\")\n",
    "    for label, count in clips_por_clase.items():\n",
    "        print(f\"   {label}: {count} clips\")\n",
    "    print(f\"   Total estimado: {total_clips} clips\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db8e1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Modelo I3D ===\n",
    "def crear_modelo_i3d():\n",
    "    \"\"\"Crea modelo I3D-ResNet50 usando PyTorchVideo Hub\"\"\"\n",
    "    try:\n",
    "        from pytorchvideo.models.hub import i3d_r50\n",
    "        \n",
    "        # Crear modelo I3D desde PyTorchVideo Hub\n",
    "        print(\"üîÑ Creando modelo I3D-ResNet50 desde PyTorchVideo Hub...\")\n",
    "        model = i3d_r50(pretrained=False)  # Sin pesos preentrenados por ahora\n",
    "        \n",
    "        print(\"‚úÖ Modelo I3D-ResNet50 creado exitosamente\")\n",
    "        return model\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"‚ùå PyTorchVideo no encontrado. Instalando...\")\n",
    "        import subprocess\n",
    "        import sys\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pytorchvideo\"])\n",
    "        print(\"‚úÖ PyTorchVideo instalado. Reintentando...\")\n",
    "        return crear_modelo_i3d()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creando modelo I3D: {e}\")\n",
    "        print(\"üîÑ Intentando m√©todo alternativo...\")\n",
    "        try:\n",
    "            # Fallback al m√©todo anterior\n",
    "            from pytorchvideo.models.resnet import create_resnet\n",
    "            model = create_resnet(\n",
    "                input_channel=3,\n",
    "                model_depth=50,\n",
    "                model_num_class=400\n",
    "            )\n",
    "            print(\"‚úÖ Modelo creado con m√©todo alternativo\")\n",
    "            return model\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Error con m√©todo alternativo: {e2}\")\n",
    "            exit(1)\n",
    "\n",
    "\n",
    "def descargar_modelo_preentrenado():\n",
    "    \"\"\"Descarga el modelo I3D preentrenado si no existe\"\"\"\n",
    "    modelo_url = \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/I3D_8x8_R50.pyth\"\n",
    "    modelo_local = PRETRAINED_MODEL\n",
    "    \n",
    "    if not os.path.exists(modelo_local):\n",
    "        print(f\"üì• Descargando modelo preentrenado I3D...\")\n",
    "        print(f\"üîó URL: {modelo_url}\")\n",
    "        try:\n",
    "            import urllib.request\n",
    "            urllib.request.urlretrieve(modelo_url, modelo_local)\n",
    "            print(f\"‚úÖ Modelo descargado: {modelo_local}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error descargando modelo: {e}\")\n",
    "            print(f\"üí° Puedes descargarlo manualmente desde: {modelo_url}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"‚úÖ Modelo preentrenado encontrado: {modelo_local}\")\n",
    "        return True\n",
    "\n",
    "def cargar_pesos_preentrenados(model, pretrained_path):\n",
    "    \"\"\"Carga pesos preentrenados desde archivos .pth o .pyth\"\"\"\n",
    "    if os.path.exists(pretrained_path):\n",
    "        try:\n",
    "            checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
    "            \n",
    "            # Detectar formato del checkpoint\n",
    "            if isinstance(checkpoint, dict) and 'model_state' in checkpoint:\n",
    "                # Formato PyTorchVideo (.pyth)\n",
    "                state_dict = checkpoint['model_state']\n",
    "                print(f\"üîç Detectado formato PyTorchVideo (.pyth)\")\n",
    "            elif isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
    "                # Formato est√°ndar con state_dict\n",
    "                state_dict = checkpoint['state_dict']\n",
    "                print(f\"üîç Detectado formato con state_dict\")\n",
    "            else:\n",
    "                # Formato directo (solo state_dict)\n",
    "                state_dict = checkpoint\n",
    "                print(f\"üîç Detectado formato directo\")\n",
    "            \n",
    "            # Intentar cargar con strict=False para ignorar incompatibilidades\n",
    "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
    "            \n",
    "            # Contar cu√°ntas capas se cargaron exitosamente\n",
    "            total_params = len(model.state_dict())\n",
    "            loaded_params = total_params - len(missing_keys)\n",
    "            \n",
    "            if len(missing_keys) > total_params * 0.5:  # Si m√°s del 50% no coincide\n",
    "                print(f\"‚ö†Ô∏è Arquitectura incompatible: {len(missing_keys)}/{total_params} capas no coinciden\")\n",
    "                print(f\"üí° Entrenando desde cero (recomendado para esta arquitectura)\")\n",
    "                return False\n",
    "            else:\n",
    "                print(f\"‚úÖ Pesos preentrenados cargados: {loaded_params}/{total_params} capas\")\n",
    "                if missing_keys:\n",
    "                    print(f\"‚ö†Ô∏è {len(missing_keys)} capas se inicializar√°n aleatoriamente\")\n",
    "                return True\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error cargando pesos: {e}\")\n",
    "            print(f\"üí° Continuando entrenamiento desde cero\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Archivo {pretrained_path} no encontrado\")\n",
    "        print(f\"üí° Entrenando desde cero\")\n",
    "        return False\n",
    "\n",
    "def modificar_capa_final(model, num_clases):\n",
    "    \"\"\"Modifica la capa final del modelo para el n√∫mero de clases objetivo\"\"\"\n",
    "    # Buscar y reemplazar la capa final\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear) and module.out_features == 400:\n",
    "            # Encontramos la capa de 400 clases\n",
    "            parent_name = '.'.join(name.split('.')[:-1]) if '.' in name else None\n",
    "            child_name = name.split('.')[-1]\n",
    "            \n",
    "            new_layer = nn.Linear(module.in_features, num_clases)\n",
    "            \n",
    "            if parent_name:\n",
    "                parent_module = dict(model.named_modules())[parent_name]\n",
    "                setattr(parent_module, child_name, new_layer)\n",
    "            else:\n",
    "                setattr(model, child_name, new_layer)\n",
    "            \n",
    "            print(f\"‚úÖ Capa final '{name}' modificada: {module.in_features} -> {num_clases}\")\n",
    "            return True\n",
    "    \n",
    "    # Fallback para modelos de torchvision\n",
    "    if hasattr(model, 'fc') and isinstance(model.fc, nn.Linear):\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_clases)\n",
    "        print(f\"‚úÖ Capa 'fc' modificada para {num_clases} clases\")\n",
    "        return True\n",
    "    \n",
    "    print(\"‚ùå No se pudo encontrar la capa final para modificar\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a6ce487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Configurando modelo I3D...\n",
      "üîÑ Creando modelo I3D-ResNet50 desde PyTorchVideo Hub...\n",
      "‚úÖ Modelo I3D-ResNet50 creado exitosamente\n",
      "\n",
      "üì¶ Verificando modelo preentrenado...\n",
      "‚úÖ Modelo preentrenado encontrado: I3D_8x8_R50_pytorchvideo.pyth\n",
      "üîç Detectado formato PyTorchVideo (.pyth)\n",
      "‚úÖ Pesos preentrenados cargados: 320/320 capas\n",
      "‚úÖ Capa final 'blocks.6.proj' modificada: 2048 -> 3\n",
      "üìä Par√°metros del modelo: 27,230,019\n"
     ]
    }
   ],
   "source": [
    "# Crear modelo\n",
    "print(\"\\nüß† Configurando modelo I3D...\")\n",
    "model = crear_modelo_i3d()\n",
    "\n",
    "# Descargar modelo preentrenado si no existe\n",
    "print(\"\\nüì¶ Verificando modelo preentrenado...\")\n",
    "descargar_modelo_preentrenado()\n",
    "\n",
    "# Cargar pesos preentrenados\n",
    "cargar_pesos_preentrenados(model, PRETRAINED_MODEL)\n",
    "\n",
    "# Modificar capa final\n",
    "modificar_capa_final(model, len(LABELS))\n",
    "\n",
    "# Mostrar informaci√≥n del modelo\n",
    "model_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"üìä Par√°metros del modelo: {model_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea50b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Entrenamiento adaptativo (CUDA/CPU) ===\n",
    "def entrenar_modelo(model, train_loader, val_loader, device, num_epochs, config):\n",
    "    \"\"\"Funci√≥n principal de entrenamiento con validaci√≥n y early stopping\"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "    # Learning rate scheduler para convergencia m√°s r√°pida\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=2\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    scaler = None\n",
    "    if config['use_mixed_precision'] and device.type == 'cuda':\n",
    "        from torch.cuda.amp import GradScaler, autocast\n",
    "        scaler = GradScaler()\n",
    "        print(\"‚úÖ Mixed Precision habilitado (AMP)\")\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        # Optimizaciones adicionales para GPU\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        # Prellenado de memoria GPU para evitar fragmentaci√≥n\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        print(f\"üöÄ Optimizaciones CUDA habilitadas (TF32, cuDNN benchmark)\")\n",
    "        print(f\"üìä VRAM disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "    print(f\"\\nüöÄ [Entrenamiento iniciado en {device}]\")\n",
    "    print(f\"üìã Configuraci√≥n: {num_epochs} √©pocas, batch_size={config['batch_size']}, lr={LEARNING_RATE}\")\n",
    "    \n",
    "    # Diagn√≥stico de utilizaci√≥n de GPU\n",
    "    if device.type == 'cuda':\n",
    "        total_vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"üí° TIPS para maximizar GPU:\")\n",
    "        print(f\"   - Si GPU < 2GB durante entrenamiento, considera aumentar batch_size\")\n",
    "        print(f\"   - VRAM total disponible: {total_vram:.1f}GB\")\n",
    "        print(f\"   - Batch size actual: {config['batch_size']}\")\n",
    "        if config['batch_size'] < 4 and total_vram > 8:\n",
    "            print(f\"   ‚ö†Ô∏è Puedes intentar batch_size m√°s grande (4-6) con {total_vram:.0f}GB VRAM\")\n",
    "\n",
    "    history = []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Modo entrenamiento\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        print(f\"\\nüìÖ --- √âpoca {epoch+1}/{num_epochs} ---\")\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            batch_start_time = time.time()\n",
    "            videos = batch['video'].to(device, non_blocking=config['pin_memory'])\n",
    "            labels = batch['label'].to(device, non_blocking=config['pin_memory'])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if scaler is not None:\n",
    "                with autocast():\n",
    "                    outputs = model(videos)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(videos)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Imprimir estado en cada lote para monitoreo detallado\n",
    "            batch_time = time.time() - batch_start_time\n",
    "            remaining_batches = len(train_loader) - batch_idx - 1\n",
    "            # ETA m√°s preciso basado en tiempo promedio por lote\n",
    "            avg_batch_time = (time.time() - epoch_start_time) / (batch_idx + 1)\n",
    "            eta_seconds = avg_batch_time * remaining_batches\n",
    "            accuracy = 100 * correct_predictions / total_samples\n",
    "            gpu_memory = torch.cuda.memory_allocated(0) / 1e9 if device.type == 'cuda' else 0\n",
    "            gpu_memory_peak = torch.cuda.max_memory_allocated(0) / 1e9 if device.type == 'cuda' else 0\n",
    "\n",
    "            # An√°lisis de distribuci√≥n de predicciones para detectar sobreajuste\n",
    "            with torch.no_grad():\n",
    "                _, predicted_batch = torch.max(outputs.data, 1)\n",
    "                unique_preds, counts = torch.unique(predicted_batch, return_counts=True)\n",
    "                pred_distribution = {LABELS[pred.item()]: count.item() for pred, count in zip(unique_preds, counts)}\n",
    "                \n",
    "            log_msg = (\n",
    "                f\"   [{batch_idx+1:4d}/{len(train_loader):4d}] \"\n",
    "                f\"Loss: {loss.item():.4f} | \"\n",
    "                f\"Acc: {accuracy:.2f}% | \"\n",
    "                f\"ETA: {int(eta_seconds):3d}s | \"\n",
    "                f\"Preds: {pred_distribution}\"\n",
    "            )\n",
    "            if device.type == 'cuda':\n",
    "                log_msg += f\" | GPU: {gpu_memory:.1f}GB\"\n",
    "            print(log_msg)\n",
    "\n",
    "            # Limpiar cache menos frecuentemente para mejor rendimiento\n",
    "            if batch_idx % 100 == 0 and device.type == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct_predictions / total_samples\n",
    "        \n",
    "        # Validaci√≥n\n",
    "        val_loss, val_accuracy = validar_modelo(model, val_loader, device, criterion)\n",
    "        \n",
    "        # Actualizar learning rate basado en val_loss\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f\"   ‚úÖ √âpoca {epoch+1} completada en {int(epoch_time)}s\")\n",
    "        print(f\"      Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%\")\n",
    "        print(f\"      Valid Loss: {val_loss:.4f}, Valid Acc: {val_accuracy:.2f}%\")\n",
    "        print(f\"      LR actual: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        # An√°lisis de sobreajuste\n",
    "        gap_loss = abs(avg_train_loss - val_loss)\n",
    "        gap_acc = abs(train_accuracy - val_accuracy)\n",
    "        \n",
    "        if gap_loss > 0.5:\n",
    "            print(f\"      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Loss = {gap_loss:.3f}\")\n",
    "        if gap_acc > 20:\n",
    "            print(f\"      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Accuracy = {gap_acc:.1f}%\")\n",
    "        if val_loss > avg_train_loss * 1.5:\n",
    "            print(f\"      ‚ö†Ô∏è Posible sobreajuste: Val Loss {val_loss:.3f} >> Train Loss {avg_train_loss:.3f}\")\n",
    "        \n",
    "        # M√©tricas de aprendizaje real\n",
    "        if epoch > 0:\n",
    "            prev_train_loss = history[-1]['train_loss'] if history else float('inf')\n",
    "            if avg_train_loss < prev_train_loss:\n",
    "                print(f\"      ‚úÖ Progreso consistente: Loss baj√≥ {prev_train_loss - avg_train_loss:.4f}\")\n",
    "            else:\n",
    "                print(f\"      üìà Loss aument√≥ desde √©poca anterior: +{avg_train_loss - prev_train_loss:.4f}\")\n",
    "\n",
    "        history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_accuracy\n",
    "        })\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"   ‚≠ê Nuevo mejor modelo guardado (Val Loss: {best_val_loss:.4f})\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"   üìâ Sin mejora por {epochs_no_improve} √©pocas\")\n",
    "\n",
    "        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"\\nüõë Early stopping en la √©poca {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        if device.type == 'cuda':\n",
    "            print(f\"      VRAM m√°xima usada: {torch.cuda.max_memory_allocated(0) / 1e9:.1f} GB\")\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    # Cargar el mejor modelo y guardarlo\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    torch.save(model.state_dict(), OUTPUT_MODEL)\n",
    "    print(f\"\\nüíæ Mejor modelo guardado como '{OUTPUT_MODEL}'\")\n",
    "\n",
    "    # Exportar m√©tricas\n",
    "    exportar_metricas_excel(history, METRICS_FILE)\n",
    "    df_metrics = pd.DataFrame(history)\n",
    "    df_metrics.to_excel(METRICS_FILE, index=False)\n",
    "    print(f\"üìä M√©tricas de entrenamiento guardadas en '{METRICS_FILE}'\")\n",
    "\n",
    "# === Validaci√≥n y Early Stopping ===\n",
    "def validar_modelo(model, dataloader, device, criterion):\n",
    "    \"\"\"Eval√∫a el modelo en el conjunto de validaci√≥n\"\"\"\n",
    "    model.eval()  # Modo evaluaci√≥n\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():  # No calcular gradientes\n",
    "        for batch in dataloader:\n",
    "            videos = batch['video'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(videos)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = 100 * correct_predictions / total_samples\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def exportar_metricas_excel(history, filepath):\n",
    "    \"\"\"Exporta el historial de m√©tricas a un archivo Excel\"\"\"\n",
    "    try:\n",
    "        df = pd.DataFrame(history)\n",
    "        df.to_excel(filepath, index=False)\n",
    "        print(f\"\\nüìä M√©tricas exportadas exitosamente a '{filepath}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è Error exportando m√©tricas a Excel: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba949b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Buscando videos de ENTRENAMIENTO en: ./tav_clean/training\n",
      "‚úÖ Total de videos de entrenamiento: 274\n",
      "\n",
      "üìä [Resumen de videos por clase]\n",
      "   Normal: 115 videos\n",
      "   Robo: 83 videos\n",
      "   Violencia: 76 videos\n",
      "\n",
      "\n",
      "üìÇ Buscando videos de VALIDACI√ìN en: ./tav_clean/validacion\n",
      "‚úÖ Total de videos de validaci√≥n: 57\n",
      "\n",
      "üìä [Resumen de videos por clase]\n",
      "   Normal: 17 videos\n",
      "   Robo: 22 videos\n",
      "   Violencia: 18 videos\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Recolectar videos de entrenamiento y validaci√≥n\n",
    "print(f\"\\nüìÇ Buscando videos de ENTRENAMIENTO en: {TRAIN_DIR}\")\n",
    "train_video_paths = recolectar_videos(TRAIN_DIR)\n",
    "if not train_video_paths:\n",
    "    print(\"‚ùå No se encontraron videos de entrenamiento. Verifica la estructura de carpetas.\")\n",
    "\n",
    "print(f\"‚úÖ Total de videos de entrenamiento: {len(train_video_paths)}\")\n",
    "contar_videos_por_etiqueta(train_video_paths)\n",
    "\n",
    "print(f\"\\nüìÇ Buscando videos de VALIDACI√ìN en: {VALIDATION_DIR}\")\n",
    "val_video_paths = recolectar_videos(VALIDATION_DIR)\n",
    "if not val_video_paths:\n",
    "    print(\"‚ùå No se encontraron videos de validaci√≥n. Verifica la estructura de carpetas.\")\n",
    "\n",
    "print(f\"‚úÖ Total de videos de validaci√≥n: {len(val_video_paths)}\")\n",
    "contar_videos_por_etiqueta(val_video_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39123752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Creando datasets con sliding window...\n",
      "üìä Total de clips generados: 15405\n",
      "üìä Total de clips generados: 2277\n",
      "‚úÖ DataLoaders creados: 3851 batches de entrenamiento, 570 batches de validaci√≥n\n"
     ]
    }
   ],
   "source": [
    "# Crear datasets para entrenamiento y validaci√≥n\n",
    "print(\"\\nüîÑ Creando datasets con sliding window...\")\n",
    "train_dataset = SlidingWindowVideoDataset(\n",
    "    video_paths=train_video_paths,\n",
    "    clip_duration=CLIP_DURATION,\n",
    "    stride=STRIDE,\n",
    "    num_frames=NUM_FRAMES\n",
    ")\n",
    "val_dataset = SlidingWindowVideoDataset(\n",
    "    video_paths=val_video_paths,\n",
    "    clip_duration=CLIP_DURATION,\n",
    "    stride=STRIDE,\n",
    "    num_frames=NUM_FRAMES\n",
    ")\n",
    "\n",
    "# Crear dataloaders para entrenamiento y validaci√≥n con optimizaciones\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=config['pin_memory'],\n",
    "    persistent_workers=config['num_workers'] > 0,\n",
    "    prefetch_factor=2 if config['num_workers'] > 0 else 2,  # Precargar m√°s datos\n",
    "    drop_last=True  # Evitar lotes incompletos que pueden ser menos eficientes\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=config['pin_memory'],\n",
    "    persistent_workers=config['num_workers'] > 0,\n",
    "    prefetch_factor=2 if config['num_workers'] > 0 else 2\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ DataLoaders creados: {len(train_loader)} batches de entrenamiento, {len(val_loader)} batches de validaci√≥n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f0325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mixed Precision habilitado (AMP)\n",
      "üöÄ Optimizaciones CUDA habilitadas (TF32, cuDNN benchmark)\n",
      "üìä VRAM disponible: 4.3 GB\n",
      "\n",
      "üöÄ [Entrenamiento iniciado en cuda:0]\n",
      "üìã Configuraci√≥n: 30 √©pocas, batch_size=4, lr=0.0001\n",
      "üí° TIPS para maximizar GPU:\n",
      "   - Si GPU < 2GB durante entrenamiento, considera aumentar batch_size\n",
      "   - VRAM total disponible: 4.3GB\n",
      "   - Batch size actual: 4\n",
      "\n",
      "üìÖ --- √âpoca 1/30 ---\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Entrenar\n",
    "entrenar_modelo(model, train_loader, val_loader, device, EPOCHS, config)\n",
    "\n",
    "print(\"\\nüéâ ¬°Entrenamiento completado!\")\n",
    "if device.tyspe == 'cuda':\n",
    "    print(f\"üèÅ VRAM final usada: {torch.cuda.memory_allocated(0) / 1e9:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162dac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuraci√≥n adaptativa (CUDA/CPU) ===\n",
    "TRAIN_DIR = \"./tav_raw/training\"\n",
    "VALIDATION_DIR = \"./tav_raw/validacion\"\n",
    "CLIP_DURATION = 2.56  # segundos\n",
    "STRIDE = 1.0  # segundos\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "EARLY_STOPPING_PATIENCE = 3\n",
    "OUTPUT_MODEL = \"i3d_finetuned_violencia_robo_normal.pth\"\n",
    "METRICS_FILE = \"training_metrics.xlsx\"\n",
    "PRETRAINED_MODEL = \"I3D_8x8_R50_pytorchvideo.pyth\"  # Formato PyTorchVideo\n",
    "LABELS = [\"Normal\", \"Robo\", \"Violencia\"]\n",
    "TARGET_SIZE = (224, 224)\n",
    "NUM_FRAMES = 64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
