{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f203bf6",
   "metadata": {},
   "source": [
    "#Proyecto de T√≥picos de An√°lisis de Video\n",
    "Nicol√°s Sep√∫lveda - Sebasti√°n Paillao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64f487c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nic_s\\anaconda3\\envs\\deepgpu\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fada7e4",
   "metadata": {},
   "source": [
    "Configuraci√≥n general e importaciones importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc5a2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === Configuraci√≥n (CUDA/CPU) ===\n",
    "LABEL_SMOOTH = 0.10 \n",
    "CLIP_DURATION = 2.56  # segundos\n",
    "STRIDE = 2.1  # segundos\n",
    "PRETRAINED_MODEL = \"I3D_8x8_R50_pytorchvideo.pyth\"  # Formato PyTorchVideo\n",
    "LABELS = [\"Normal\", \"Robo\", \"Violencia\"]\n",
    "TARGET_SIZE = (224, 224)\n",
    "NUM_FRAMES = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0395e5f",
   "metadata": {},
   "source": [
    "Configuraci√≥n del hardware a utilizar, seg√∫n disponibilidad de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c39c7f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VRAM detectada: 4.3 GB\n",
      "‚ö° Configuraci√≥n optimizada: batch_size=3, num_workers=0\n",
      "üöÄ GPU detectada: NVIDIA GeForce GTX 1650 Ti\n",
      "üíæ VRAM total: 4.3 GB\n",
      "üñ•Ô∏è  Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "def get_hardware_config():\n",
    "    if torch.cuda.is_available():\n",
    "        # Detectar capacidad de VRAM autom√°ticamente\n",
    "        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"üîç VRAM detectada: {gpu_memory_gb:.1f} GB\")\n",
    "        \n",
    "        # Configuraci√≥n solicitada:\n",
    "        batch_size = 3\n",
    "        num_workers = 0\n",
    "            \n",
    "        print(f\"‚ö° Configuraci√≥n optimizada: batch_size={batch_size}, num_workers={num_workers}\")\n",
    "        \n",
    "        return {\n",
    "            'batch_size': batch_size,\n",
    "            'num_workers': num_workers,\n",
    "            'pin_memory': True,\n",
    "            'use_mixed_precision': True,\n",
    "            'cuda_device': 0\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'batch_size': 1,  # CPU usa batch size m√°s peque√±o\n",
    "            'num_workers': 0,\n",
    "            'pin_memory': False,\n",
    "            'use_mixed_precision': False,\n",
    "            'cuda_device': None\n",
    "        }\n",
    "\n",
    "# Obtener configuraci√≥n seg√∫n hardware disponible\n",
    "config = get_hardware_config()\n",
    "\n",
    "# Verificar CUDA y configurar device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(f'cuda:{config[\"cuda_device\"]}')\n",
    "    gpu_name = torch.cuda.get_device_name(config[\"cuda_device\"])\n",
    "    gpu_memory = torch.cuda.get_device_properties(config[\"cuda_device\"]).total_memory / 1e9\n",
    "    print(f\"üöÄ GPU detectada: {gpu_name}\")\n",
    "    print(f\"üíæ VRAM total: {gpu_memory:.1f} GB\")\n",
    "    print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "    \n",
    "    # Limpiar cache de GPU\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f\"‚ö†Ô∏è  CUDA no disponible, usando CPU\")\n",
    "    print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "    print(f\"üí° Para usar GPU, ejecuta: setup_cuda.bat\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b54658",
   "metadata": {},
   "source": [
    "#### Clase para clips con Sliding Window\n",
    "Se crea una clase para generar clips usando una sliding window. Esto ser√° √∫til para usar sobre los videos del dataset, tanto para el entrenamiento como para el testeo, pues I3D y modelos similares trabajan con clips, mientras que los videos del dataset pueden ser largos, por lo que necesitaremos crear un conjunto de clips a partir de los videos. Estos se armar√°n con una cantidad de frames indicada, dividiendo el video original considerando el stride dado, para solapamiento de los clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f6440970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Dataset con sliding window ===\n",
    "class SlidingWindowVideoDataset(Dataset):\n",
    "    def __init__(self, video_paths, clip_duration, stride, num_frames=64, transform=None):\n",
    "        self.clips = []\n",
    "        self.clip_duration = clip_duration\n",
    "        self.stride = stride\n",
    "        self.num_frames = num_frames\n",
    "        self.transform = None\n",
    "        \n",
    "        # Generar todos los clips con sliding window\n",
    "        for video_path, label in video_paths:\n",
    "            clips_from_video = self._generate_clips(video_path, label)\n",
    "            self.clips.extend(clips_from_video)\n",
    "        \n",
    "        print(f\"üìä Total de clips generados: {len(self.clips)}\")\n",
    "    \n",
    "    def _generate_clips(self, video_path, label):\n",
    "        \"\"\"Genera clips usando sliding window para un video\"\"\"\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            cap.release()\n",
    "            \n",
    "            if fps <= 0:\n",
    "                return []\n",
    "            \n",
    "            video_duration = total_frames / fps\n",
    "            clips = []\n",
    "            \n",
    "            start_time = 0.0\n",
    "            while start_time + self.clip_duration <= video_duration:\n",
    "                start_frame = int(start_time * fps)\n",
    "                end_frame = int((start_time + self.clip_duration) * fps)\n",
    "                \n",
    "                clips.append({\n",
    "                    'video_path': video_path,\n",
    "                    'label': label,\n",
    "                    'start_frame': start_frame,\n",
    "                    'end_frame': end_frame,\n",
    "                    'fps': fps\n",
    "                })\n",
    "                \n",
    "                start_time += self.stride\n",
    "            \n",
    "            return clips\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error procesando {video_path}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.clips)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        clip_info = self.clips[idx]\n",
    "        \n",
    "        # Cargar frames del clip\n",
    "        frames = self._load_video_clip(\n",
    "            clip_info['video_path'],\n",
    "            clip_info['start_frame'],\n",
    "            clip_info['end_frame']\n",
    "        )\n",
    "        \n",
    "        # Convertir a tensor y aplicar transformaciones\n",
    "        video_tensor = self._preprocess_frames(frames)\n",
    "        \n",
    "        return {\n",
    "            'video': video_tensor,\n",
    "            'label': torch.tensor(clip_info['label'], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    def _load_video_clip(self, video_path, start_frame, end_frame):\n",
    "        \"\"\"Carga frames espec√≠ficos de un video\"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        \n",
    "        # Calcular √≠ndices de frames a extraer\n",
    "        total_clip_frames = end_frame - start_frame\n",
    "        if total_clip_frames <= 0:\n",
    "            cap.release()\n",
    "            return [np.zeros((*TARGET_SIZE, 3), dtype=np.uint8)] * self.num_frames\n",
    "        \n",
    "        # Submuestreo uniforme para obtener NUM_FRAMES\n",
    "        frame_indices = np.linspace(start_frame, end_frame-1, self.num_frames, dtype=int)\n",
    "        \n",
    "        for frame_idx in frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if ret:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = cv2.resize(frame, TARGET_SIZE)\n",
    "                frames.append(frame)\n",
    "            else:\n",
    "                # Usar √∫ltimo frame v√°lido si hay error\n",
    "                if frames:\n",
    "                    frames.append(frames[-1])\n",
    "                else:\n",
    "                    frames.append(np.zeros((*TARGET_SIZE, 3), dtype=np.uint8))\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        # Asegurar que tenemos exactamente NUM_FRAMES\n",
    "        while len(frames) < self.num_frames:\n",
    "            frames.append(frames[-1] if frames else np.zeros((*TARGET_SIZE, 3), dtype=np.uint8))\n",
    "        \n",
    "        return frames[:self.num_frames]\n",
    "    \n",
    "    def _preprocess_frames(self, frames):\n",
    "        \"\"\"Convierte frames a tensor y aplica transformaciones\"\"\"\n",
    "        processed = []\n",
    "        \n",
    "        # ---------- A) aplica la misma aleatoriedad a todo el clip ----------\n",
    "        if self.transform is not None:\n",
    "            # Para que flip y jitter sean coherentes en los 16 frames,\n",
    "            # fijamos una semilla por clip (opcional pero pr√°ctico).\n",
    "            seed = torch.randint(0, 10_000, (1,)).item()\n",
    "        \n",
    "        for f in frames:\n",
    "            img = f  # ndarray RGB [H,W,3]\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                torch.manual_seed(seed)       # ‚ûå misma rand para el clip\n",
    "                img = self.transform(img)     # devuelve Tensor CxHxW [0,1] y normalizado\n",
    "            else:\n",
    "                img = torch.from_numpy(img).permute(2,0,1).float() / 255.\n",
    "\n",
    "            processed.append(img)\n",
    "        \n",
    "        video_tensor = torch.stack(processed, dim=1)  # [C, T, H, W]\n",
    "        return video_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef82d3b",
   "metadata": {},
   "source": [
    "#### Transformaciones\n",
    "Se aplicar√°n las siguientes transformaciones a los videos. Para el train set se aplican un conjunto de transformaciones para hacer data augmentation. Para validaci√≥n y test, transformaciones enfocadas a normalizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4c90264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# ---- transform para ENTRENAMIENTO ----\n",
    "TRAIN_TRANSFORM = transforms.Compose([\n",
    "    transforms.ToPILImage(),                       # ndarray ‚Üí PIL\n",
    "    transforms.RandomResizedCrop(TARGET_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.12, 0.12),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.45]*3, [0.225]*3),\n",
    "    transforms.RandomErasing(p=0.25, scale=(0.02,0.12))\n",
    "])\n",
    "\n",
    "# ---- transform para VALIDACI√ìN / TEST ----\n",
    "VAL_TRANSFORM = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(TARGET_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.45, 0.45, 0.45],\n",
    "                         [0.225,0.225,0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0f975a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Funciones de utilidad ===\n",
    "def recolectar_videos(base_dir):\n",
    "    \"\"\"Recolecta todas las rutas de videos con sus etiquetas de forma recursiva\"\"\"\n",
    "    video_paths = []\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(LABELS)}\n",
    "    \n",
    "    for label in LABELS:\n",
    "        label_dir = Path(base_dir) / label\n",
    "        if not label_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è Directorio no encontrado: {label_dir}\")\n",
    "            continue\n",
    "        \n",
    "        # B√∫squeda recursiva de videos .mp4\n",
    "        for video_file in label_dir.glob(\"**/*.mp4\"):\n",
    "            video_paths.append((str(video_file), label_to_idx[label]))\n",
    "    \n",
    "    return video_paths\n",
    "\n",
    "def contar_videos_por_etiqueta(video_paths):\n",
    "    \"\"\"Cuenta videos por cada etiqueta\"\"\"\n",
    "    conteo = defaultdict(int)\n",
    "    for _, label_idx in video_paths:\n",
    "        label_name = LABELS[label_idx]\n",
    "        conteo[label_name] += 1\n",
    "    \n",
    "    print(\"\\nüìä [Resumen de videos por clase]\")\n",
    "    for label, count in conteo.items():\n",
    "        print(f\"   {label}: {count} videos\")\n",
    "    print()\n",
    "\n",
    "def estimar_clips_totales(video_paths):\n",
    "    \"\"\"Estima el n√∫mero total de clips que se generar√°n\"\"\"\n",
    "    total_clips = 0\n",
    "    clips_por_clase = defaultdict(int)\n",
    "    \n",
    "    for video_path, label_idx in video_paths:\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            cap.release()\n",
    "            \n",
    "            if fps > 0:\n",
    "                video_duration = total_frames / fps\n",
    "                num_clips = max(0, int((video_duration - CLIP_DURATION) / STRIDE) + 1)\n",
    "                total_clips += num_clips\n",
    "                clips_por_clase[LABELS[label_idx]] += num_clips\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error estimando clips para {video_path}: {e}\")\n",
    "    \n",
    "    print(\"üìä [Estimaci√≥n de clips por sliding window]\")\n",
    "    for label, count in clips_por_clase.items():\n",
    "        print(f\"   {label}: {count} clips\")\n",
    "    print(f\"   Total estimado: {total_clips} clips\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee529c",
   "metadata": {},
   "source": [
    "### Armado del dataset\n",
    "Las siguientes funciones son para armar el conjunto de clips que ser√° utilizado por el modelo. Se utiliza la clase Sliding Window anteriormente definida para la creaci√≥n de los clips, incluyendo las transformaciones definidas anteriormente seg√∫n si los videos son para entrenamiento o para validaci√≥n/test, utilizando DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69e81210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recolectar videos de entrenamiento y validaci√≥n\n",
    "def recolectar_datasets():\n",
    "    print(f\"\\nüìÇ Buscando videos de ENTRENAMIENTO en: {TRAIN_DIR}\")\n",
    "    train_video_paths = recolectar_videos(TRAIN_DIR)\n",
    "    if not train_video_paths:\n",
    "        print(\"‚ùå No se encontraron videos de entrenamiento. Verifica la estructura de carpetas.\")\n",
    "\n",
    "    print(f\"‚úÖ Total de videos de entrenamiento: {len(train_video_paths)}\")\n",
    "    contar_videos_por_etiqueta(train_video_paths)\n",
    "\n",
    "    print(f\"\\nüìÇ Buscando videos de VALIDACI√ìN en: {VALIDATION_DIR}\")\n",
    "    val_video_paths = recolectar_videos(VALIDATION_DIR)\n",
    "    if not val_video_paths:\n",
    "        print(\"‚ùå No se encontraron videos de validaci√≥n. Verifica la estructura de carpetas.\")\n",
    "\n",
    "    print(f\"‚úÖ Total de videos de validaci√≥n: {len(val_video_paths)}\")\n",
    "    contar_videos_por_etiqueta(val_video_paths)\n",
    "\n",
    "    # Crear datasets para entrenamiento y validaci√≥n\n",
    "    print(\"\\nüîÑ Creando datasets con sliding window...\")\n",
    "    train_dataset = SlidingWindowVideoDataset(\n",
    "        video_paths=train_video_paths,\n",
    "        clip_duration=CLIP_DURATION,\n",
    "        stride=STRIDE,\n",
    "        num_frames=NUM_FRAMES,\n",
    "        transform=TRAIN_TRANSFORM\n",
    "    )\n",
    "    val_dataset = SlidingWindowVideoDataset(\n",
    "        video_paths=val_video_paths,\n",
    "        clip_duration=CLIP_DURATION,\n",
    "        stride=STRIDE,\n",
    "        num_frames=NUM_FRAMES,\n",
    "        transform=VAL_TRANSFORM\n",
    "    )\n",
    "\n",
    "    # Crear dataloaders para entrenamiento y validaci√≥n con optimizaciones\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=config['num_workers'],\n",
    "        pin_memory=config['pin_memory'],\n",
    "        drop_last=True,\n",
    "        **({\"persistent_workers\": True, \"prefetch_factor\": 2} if config['num_workers'] > 0 else {})\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=config['num_workers'],\n",
    "        pin_memory=config['pin_memory'],\n",
    "        drop_last=True,\n",
    "        **({\"persistent_workers\": True, \"prefetch_factor\": 2} if config['num_workers'] > 0 else {})\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ DataLoaders creados: {len(train_loader)} batches de entrenamiento, {len(val_loader)} batches de validaci√≥n\")\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8467e825",
   "metadata": {},
   "source": [
    "### Creaci√≥n del modelo\n",
    "Funciones para creaci√≥n del modelo y carga de pesos preentrenados cuando se utilicen. Se parametrizan algunas opciones para la creaci√≥n, como el drop_out, la cantidad de clases y el congelamiento de capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Modelo I3D parametrizado ===\n",
    "from typing import Iterable, Union, Optional\n",
    "import torch.nn as nn\n",
    "from pytorchvideo.models.hub import i3d_r50\n",
    "\n",
    "\n",
    "def crear_modelo_i3d(\n",
    "        dropout_p: Optional[float] = None,                   \n",
    "        freeze_until: Union[int, Iterable[int]] = 4,\n",
    "        pretrain_path: Optional[str] = PRETRAINED_MODEL,\n",
    "        num_clases: int = 3,\n",
    "        freeze_backbone: bool = True\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    Devuelve un I3D-ResNet50 con la cabeza adaptada a `num_clases`.\n",
    "\n",
    "    ‚Ä¢ `dropout_p`     ‚Äì probabilidad de Dropout en la head.\n",
    "    ‚Ä¢ `freeze_until`  ‚Äì hasta qu√© bloque congelar:\n",
    "        ‚Äì int  : congela bloques 0 ‚Ä¶ freeze_until (incl.).\n",
    "        ‚Äì iter : congela los √≠ndices listados, e.g. (0,1,2,5).\n",
    "    ‚Ä¢ `pretrain_path` ‚Äì ruta a pesos preentrenados (.pyth) o None.\n",
    "    ‚Ä¢ `freeze_backbone` False ‚Üí no congela nada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"üîÑ Creando modelo I3D-ResNet50‚Ä¶\")\n",
    "        model = i3d_r50(pretrained=False)\n",
    "\n",
    "        # 1) Pesos preentrenados\n",
    "        if pretrain_path:\n",
    "            cargar_pesos_preentrenados(model, pretrain_path)\n",
    "\n",
    "        # 2) Head: Dropout + proyecci√≥n\n",
    "        head = model.blocks[-1]\n",
    "        if dropout_p is None:\n",
    "            head.dropout = nn.Identity()          # arquitectura sin Dropout\n",
    "            print(\"‚úÖ Head: SIN Dropout\")\n",
    "        else:\n",
    "            head.dropout = nn.Dropout(dropout_p)\n",
    "            print(f\"‚úÖ Head: Dropout p={dropout_p}\")\n",
    "\n",
    "        head.proj = nn.Linear(head.proj.in_features, num_clases)\n",
    "        print(f\"   ‚Ü≥ proyecci√≥n ‚Üí {num_clases} clases\")\n",
    "\n",
    "        # 3) Congelado selectivo del backbone\n",
    "        if freeze_backbone:\n",
    "            if isinstance(freeze_until, int):\n",
    "                freeze_set = {f\"blocks.{i}\" for i in range(freeze_until + 1)}\n",
    "            else:                       # iterable de √≠ndices\n",
    "                freeze_set = {f\"blocks.{i}\" for i in freeze_until}\n",
    "\n",
    "            frozen, trainable = 0, 0\n",
    "            for name, p in model.named_parameters():\n",
    "                block_tag = '.'.join(name.split('.', 2)[:2])   # \"blocks.X\"\n",
    "                if block_tag in freeze_set:\n",
    "                    p.requires_grad = False\n",
    "                    frozen += 1\n",
    "                else:\n",
    "                    trainable += 1\n",
    "            print(f\"üßä  Capas congeladas: {frozen}  |  Entrenables: {trainable}\")\n",
    "\n",
    "        return model\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"‚ùå PyTorchVideo no encontrado. Instalando...\")\n",
    "        import subprocess\n",
    "        import sys\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pytorchvideo\"])\n",
    "        print(\"‚úÖ PyTorchVideo instalado. Reintentando...\")\n",
    "        return crear_modelo_i3d()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creando modelo I3D: {e}\")\n",
    "        print(\"üîÑ Intentando m√©todo alternativo...\")\n",
    "        try:\n",
    "            # Fallback al m√©todo anterior\n",
    "            from pytorchvideo.models.resnet import create_resnet\n",
    "            model = create_resnet(\n",
    "                input_channel=3,\n",
    "                model_depth=50,\n",
    "                model_num_class=400\n",
    "            )\n",
    "            print(\"‚úÖ Modelo creado con m√©todo alternativo\")\n",
    "            return model\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Error con m√©todo alternativo: {e2}\")\n",
    "            exit(1)\n",
    "\n",
    "\n",
    "def descargar_modelo_preentrenado():\n",
    "    \"\"\"Descarga el modelo I3D preentrenado si no existe\"\"\"\n",
    "    modelo_url = \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/I3D_8x8_R50.pyth\"\n",
    "    modelo_local = PRETRAINED_MODEL\n",
    "    \n",
    "    if not os.path.exists(modelo_local):\n",
    "        print(f\"üì• Descargando modelo preentrenado I3D...\")\n",
    "        print(f\"üîó URL: {modelo_url}\")\n",
    "        try:\n",
    "            import urllib.request\n",
    "            urllib.request.urlretrieve(modelo_url, modelo_local)\n",
    "            print(f\"‚úÖ Modelo descargado: {modelo_local}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error descargando modelo: {e}\")\n",
    "            print(f\"üí° Puedes descargarlo manualmente desde: {modelo_url}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"‚úÖ Modelo preentrenado encontrado: {modelo_local}\")\n",
    "        return True\n",
    "\n",
    "def cargar_pesos_preentrenados(model, pretrained_path):\n",
    "    \"\"\"Carga pesos preentrenados desde archivos .pth o .pyth\"\"\"\n",
    "    if os.path.exists(pretrained_path):\n",
    "        try:\n",
    "            checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
    "            \n",
    "            # Detectar formato del checkpoint\n",
    "            if isinstance(checkpoint, dict) and 'model_state' in checkpoint:\n",
    "                # Formato PyTorchVideo (.pyth)\n",
    "                state_dict = checkpoint['model_state']\n",
    "                print(f\"üîç Detectado formato PyTorchVideo (.pyth)\")\n",
    "            elif isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
    "                # Formato est√°ndar con state_dict\n",
    "                state_dict = checkpoint['state_dict']\n",
    "                print(f\"üîç Detectado formato con state_dict\")\n",
    "            else:\n",
    "                # Formato directo (solo state_dict)\n",
    "                state_dict = checkpoint\n",
    "                print(f\"üîç Detectado formato directo\")\n",
    "            \n",
    "            # Intentar cargar con strict=False para ignorar incompatibilidades\n",
    "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
    "            \n",
    "            # Contar cu√°ntas capas se cargaron exitosamente\n",
    "            total_params = len(model.state_dict())\n",
    "            loaded_params = total_params - len(missing_keys)\n",
    "            \n",
    "            if len(missing_keys) > total_params * 0.5:  # Si m√°s del 50% no coincide\n",
    "                print(f\"‚ö†Ô∏è Arquitectura incompatible: {len(missing_keys)}/{total_params} capas no coinciden\")\n",
    "                print(f\"üí° Entrenando desde cero (recomendado para esta arquitectura)\")\n",
    "                return False\n",
    "            else:\n",
    "                print(f\"‚úÖ Pesos preentrenados cargados: {loaded_params}/{total_params} capas\")\n",
    "                if missing_keys:\n",
    "                    print(f\"‚ö†Ô∏è {len(missing_keys)} capas se inicializar√°n aleatoriamente\")\n",
    "                return True\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error cargando pesos: {e}\")\n",
    "            print(f\"üí° Continuando entrenamiento desde cero\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Archivo {pretrained_path} no encontrado\")\n",
    "        print(f\"üí° Entrenando desde cero\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264d3fbb",
   "metadata": {},
   "source": [
    "## Funci√≥n de entrenamiento\n",
    "En esta funci√≥n se condensa todo el flujo de entrenamiento de un modelo, a partir de distintos par√°metros y utilizando los clips de train y validaci√≥n construidos con dataLoader y Sliding Window. Se utiliza Mixed Precision y otras adaptaciones para mejorar rendimiento de uso de GPU. Se incluye un early stopping y se guardan los checkpoints (en caso de interrupci√≥n para continuar entrenamiento) y el mejor modelo en caso de detectar sobre-ajuste. Adem√°s, se exportan en un .csv las m√©tricas del entrenamiento, para su posterior an√°lisis. Se incorporan ac√° diferentes configuraciones como el uso de un scheduler para el LR y un batch accumulation, para aumentar el tama√±o del batch virtualmente, dando mayor estabilidad al entrenamiento, en condiciones donde la GPU no sea capaz de manejar un batch real m√°s grande. Se incluye una etapa de validaci√≥n tras cada √©poca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Entrenamiento adaptativo (CUDA/CPU) ===\n",
    "def entrenar_modelo(model, train_loader, val_loader, device, num_epochs, config,\n",
    "                    class_weights=None):\n",
    "    \"\"\"Funci√≥n principal de entrenamiento con validaci√≥n y early stopping\"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=LEARNING_RATE, weight_decay=5e-4\n",
    "    )\n",
    "    # Learning rate scheduler para convergencia m√°s r√°pida\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.3, patience=2\n",
    "    )\n",
    "    LABEL_SMOOTH = 0.10    \n",
    "\n",
    "    if class_weights is not None:\n",
    "        criterion = nn.CrossEntropyLoss(\n",
    "            weight=class_weights.to(device),\n",
    "            label_smoothing=LABEL_SMOOTH\n",
    "        )\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss(\n",
    "            label_smoothing=LABEL_SMOOTH\n",
    "        )\n",
    "\n",
    "    \n",
    "    scaler = None\n",
    "    if config['use_mixed_precision'] and device.type == 'cuda':\n",
    "        from torch.cuda.amp import GradScaler, autocast\n",
    "        scaler = GradScaler()\n",
    "        print(\"‚úÖ Mixed Precision habilitado (AMP)\")\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        # Optimizaciones adicionales para GPU\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        # Prellenado de memoria GPU para evitar fragmentaci√≥n\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        print(f\"üöÄ Optimizaciones CUDA habilitadas (TF32, cuDNN benchmark)\")\n",
    "        print(f\"üìä VRAM disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "    print(f\"\\nüöÄ [Entrenamiento iniciado en {device}]\")\n",
    "    print(f\"üìã Configuraci√≥n: {num_epochs} √©pocas, batch_size={config['batch_size']}, lr={LEARNING_RATE}\")\n",
    "    \n",
    "    # Diagn√≥stico de utilizaci√≥n de GPU\n",
    "    if device.type == 'cuda':\n",
    "        total_vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"üí° TIPS para maximizar GPU:\")\n",
    "        print(f\"   - Si GPU < 2GB durante entrenamiento, considera aumentar batch_size\")\n",
    "        print(f\"   - VRAM total disponible: {total_vram:.1f}GB\")\n",
    "        print(f\"   - Batch size actual: {config['batch_size']}\")\n",
    "        if config['batch_size'] < 4 and total_vram > 8:\n",
    "            print(f\"   ‚ö†Ô∏è Puedes intentar batch_size m√°s grande (4-6) con {total_vram:.0f}GB VRAM\")\n",
    "\n",
    "    history = []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    # Acumulaci√≥n de gradientes\n",
    "    accum_steps = 2\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Modo entrenamiento\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        print(f\"\\nüìÖ --- √âpoca {epoch+1}/{num_epochs} ---\")\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            if batch_idx == 0:\n",
    "                print(\"‚úÖ Primer batch cargado y procesado.\")            \n",
    "            batch_start_time = time.time()\n",
    "            videos = batch['video'].to(device, non_blocking=config['pin_memory'])\n",
    "            labels = batch['label'].to(device, non_blocking=config['pin_memory'])\n",
    "            \n",
    "            # Adaptacion para acumulaci√≥n de gradientes\n",
    "            if (batch_idx % accum_steps) == 0:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if scaler is not None:\n",
    "                with autocast():\n",
    "                    outputs = model(videos)\n",
    "                    loss = criterion(outputs, labels) / accum_steps \n",
    "                scaler.scale(loss).backward()\n",
    "            else:\n",
    "                outputs = model(videos)\n",
    "                loss = criterion(outputs, labels) / accum_steps\n",
    "                loss.backward()\n",
    "\n",
    "            # Actualizar gradientes cada accum_steps\n",
    "            if (batch_idx + 1) % accum_steps == 0:\n",
    "                if scaler is not None:          # ‚îÄ‚îÄ caso AMP\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:                            # ‚îÄ‚îÄ caso normal\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * accum_steps\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Imprimir estado en cada lote para monitoreo detallado\n",
    "            batch_time = time.time() - batch_start_time\n",
    "            remaining_batches = len(train_loader) - batch_idx - 1\n",
    "            # ETA m√°s preciso basado en tiempo promedio por lote\n",
    "            avg_batch_time = (time.time() - epoch_start_time) / (batch_idx + 1)\n",
    "            eta_seconds = avg_batch_time * remaining_batches\n",
    "            accuracy = 100 * correct_predictions / total_samples\n",
    "            gpu_memory = torch.cuda.memory_allocated(0) / 1e9 if device.type == 'cuda' else 0\n",
    "            gpu_memory_peak = torch.cuda.max_memory_allocated(0) / 1e9 if device.type == 'cuda' else 0\n",
    "\n",
    "            # An√°lisis de distribuci√≥n de predicciones para detectar sobreajuste\n",
    "            with torch.no_grad():\n",
    "                _, predicted_batch = torch.max(outputs.data, 1)\n",
    "                unique_preds, counts = torch.unique(predicted_batch, return_counts=True)\n",
    "                pred_distribution = {LABELS[pred.item()]: count.item() for pred, count in zip(unique_preds, counts)}\n",
    "                \n",
    "            log_msg = (\n",
    "                f\"   [{batch_idx+1:4d}/{len(train_loader):4d}] \"\n",
    "                f\"Loss: {(loss.item()*accum_steps):.4f} | \"\n",
    "                f\"Acc: {accuracy:.2f}% | \"\n",
    "                f\"ETA: {int(eta_seconds):3d}s | \"\n",
    "                f\"Preds: {pred_distribution}\"\n",
    "            )\n",
    "            if device.type == 'cuda':\n",
    "                log_msg += f\" | GPU: {gpu_memory:.1f}GB / peak: {gpu_memory_peak:.1f}GB\"\n",
    "            if batch_idx % 200 == 0 or batch_idx == len(train_loader) - 1:\n",
    "                print(log_msg)                \n",
    "\n",
    "            # Limpiar cache menos frecuentemente para mejor rendimiento\n",
    "            if batch_idx % 100 == 0 and device.type == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct_predictions / total_samples\n",
    "        \n",
    "        if (len(train_loader) % accum_steps) != 0:\n",
    "            if scaler is not None:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Validaci√≥n\n",
    "        print(f\"\\nüîç Validando al final de la √©poca {epoch+1}...\")\n",
    "        val_loss, val_accuracy = validar_modelo(model, val_loader, device, criterion)\n",
    "        \n",
    "        # Actualizar learning rate basado en val_loss\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f\"   ‚úÖ √âpoca {epoch+1} completada en {int(epoch_time)}s\")\n",
    "        print(f\"      Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%\")\n",
    "        print(f\"      Valid Loss: {val_loss:.4f}, Valid Acc: {val_accuracy:.2f}%\")\n",
    "        print(f\"      LR actual: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        # An√°lisis de sobreajuste\n",
    "        gap_loss = abs(avg_train_loss - val_loss)\n",
    "        gap_acc = abs(train_accuracy - val_accuracy)\n",
    "        \n",
    "        if gap_loss > 0.5:\n",
    "            print(f\"      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Loss = {gap_loss:.3f}\")\n",
    "        if gap_acc > 20:\n",
    "            print(f\"      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Accuracy = {gap_acc:.1f}%\")\n",
    "        if val_loss > avg_train_loss * 1.5:\n",
    "            print(f\"      ‚ö†Ô∏è Posible sobreajuste: Val Loss {val_loss:.3f} >> Train Loss {avg_train_loss:.3f}\")\n",
    "        \n",
    "        # M√©tricas de aprendizaje real\n",
    "        if epoch > 0:\n",
    "            prev_train_loss = history[-1]['train_loss'] if history else float('inf')\n",
    "            if avg_train_loss < prev_train_loss:\n",
    "                print(f\"      ‚úÖ Progreso consistente: Loss baj√≥ {prev_train_loss - avg_train_loss:.4f}\")\n",
    "            else:\n",
    "                print(f\"      üìà Loss aument√≥ desde √©poca anterior: +{avg_train_loss - prev_train_loss:.4f}\")\n",
    "\n",
    "        # Exportar m√©tricas\n",
    "        history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_accuracy\n",
    "        })\n",
    "        \n",
    "        append_metrics_csv(history[-1], METRICS_FILE)\n",
    "\n",
    "        # Guardar checkpoint al final de cada √©poca\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,  # n√∫mero de √©poca actual\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            \"amp_scaler_state_dict\": scaler.state_dict() if scaler else None,\n",
    "            'history': history,\n",
    "            'best_val_loss': best_val_loss,\n",
    "        }\n",
    "\n",
    "        # Obs: solo guardar √∫ltimo checkpoint, en caso de interrupciones\n",
    "        torch.save(checkpoint, \"checkpoint_latest.pth\")\n",
    "        print(f\"üíæ Checkpoint N¬∞{epoch+1} guardado en checkpoint_latest.pth\")\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"   ‚≠ê Nuevo mejor modelo guardado (Val Loss: {best_val_loss:.4f})\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"   üìâ Sin mejora por {epochs_no_improve} √©pocas\")\n",
    "\n",
    "        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"\\nüõë Early stopping en la √©poca {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        if device.type == 'cuda':\n",
    "            print(f\"      VRAM m√°xima usada: {torch.cuda.max_memory_allocated(0) / 1e9:.1f} GB\")\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    # Cargar el mejor modelo y guardarlo\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    torch.save(model.state_dict(), OUTPUT_MODEL)\n",
    "    print(f\"\\nüíæ Mejor modelo guardado como '{OUTPUT_MODEL}'\")\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# === Validaci√≥n y Early Stopping ===\n",
    "def validar_modelo(model, dataloader, device, criterion):\n",
    "    \"\"\"Eval√∫a el modelo en el conjunto de validaci√≥n\"\"\"\n",
    "    model.eval()  # Modo evaluaci√≥n\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():  # No calcular gradientes\n",
    "        for batch in dataloader:\n",
    "            videos = batch['video'].to(device, non_blocking=True)\n",
    "            labels = batch['label'].to(device, non_blocking=True)\n",
    "            \n",
    "            with autocast(enabled=device.type == \"cuda\"):\n",
    "                outputs = model(videos)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            if device.type == \"cuda\":\n",
    "                del videos, labels, outputs\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = 100 * correct_predictions / total_samples\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "import csv, os\n",
    "\n",
    "def append_metrics_csv(history_row, csv_path=\"training_metrics.csv\"):\n",
    "    \"\"\"Exporta el historial de m√©tricas a un archivo csv\"\"\"\n",
    "    header = list(history_row.keys())\n",
    "    file_exists = os.path.isfile(csv_path)\n",
    "\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=header)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(history_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a6ce487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_entrenamiento():\n",
    "    \"\"\"Funci√≥n principal para ejecutar el entrenamiento\"\"\"\n",
    "    # Crear el modelo con backbone congelado\n",
    "    print(\"\\nüß† Configurando modelo I3D...\")\n",
    "    model = crear_modelo_i3d(num_clases=len(LABELS), freeze_backbone=True)\n",
    "\n",
    "    # Descargar modelo preentrenado si no existe\n",
    "    print(\"\\nüì¶ Verificando modelo preentrenado...\")\n",
    "    descargar_modelo_preentrenado()\n",
    "\n",
    "    # Mostrar informaci√≥n del modelo\n",
    "    model_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"üìä Par√°metros del modelo: {model_params:,}\")\n",
    "\n",
    "    train_loader, val_loader = recolectar_datasets()\n",
    "    \n",
    "    # Entrenar\n",
    "    entrenar_modelo(model, train_loader, val_loader, device, EPOCHS, config)\n",
    "\n",
    "    print(\"\\nüéâ ¬°Entrenamiento completado!\")\n",
    "    if device.tyspe == 'cuda':\n",
    "        print(f\"üèÅ VRAM final usada: {torch.cuda.memory_allocated(0) / 1e9:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45824f4",
   "metadata": {},
   "source": [
    "# Primer Experimento (Dataset limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba949b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Configurando modelo I3D...\n",
      "üîÑ Creando modelo I3D-ResNet50 ‚Ä¶\n",
      "üîç Detectado formato PyTorchVideo (.pyth)\n",
      "‚úÖ Pesos preentrenados cargados: 320/320 capas\n",
      "‚úÖ Capa final adaptada ‚Üí 3 clases\n",
      "üßä  Bloques 0-3 congelados\n",
      "\n",
      "üì¶ Verificando modelo preentrenado...\n",
      "‚úÖ Modelo preentrenado encontrado: I3D_8x8_R50_pytorchvideo.pyth\n",
      "üìä Par√°metros del modelo: 27,230,019\n",
      "\n",
      "üìÇ Buscando videos de ENTRENAMIENTO en: ./tav_clean/training\n",
      "‚úÖ Total de videos de entrenamiento: 274\n",
      "\n",
      "üìä [Resumen de videos por clase]\n",
      "   Normal: 115 videos\n",
      "   Robo: 83 videos\n",
      "   Violencia: 76 videos\n",
      "\n",
      "\n",
      "üìÇ Buscando videos de VALIDACI√ìN en: ./tav_clean/validacion\n",
      "‚úÖ Total de videos de validaci√≥n: 57\n",
      "\n",
      "üìä [Resumen de videos por clase]\n",
      "   Normal: 17 videos\n",
      "   Robo: 22 videos\n",
      "   Violencia: 18 videos\n",
      "\n",
      "\n",
      "üîÑ Creando datasets con sliding window...\n",
      "üìä Total de clips generados: 7401\n",
      "üìä Total de clips generados: 1103\n",
      "‚úÖ DataLoaders creados: 3700 batches de entrenamiento, 551 batches de validaci√≥n\n",
      "‚úÖ Mixed Precision habilitado (AMP)\n",
      "üöÄ Optimizaciones CUDA habilitadas (TF32, cuDNN benchmark)\n",
      "üìä VRAM disponible: 4.3 GB\n",
      "\n",
      "üöÄ [Entrenamiento iniciado en cuda:0]\n",
      "üìã Configuraci√≥n: 10 √©pocas, batch_size=2, lr=0.0001\n",
      "üí° TIPS para maximizar GPU:\n",
      "   - Si GPU < 2GB durante entrenamiento, considera aumentar batch_size\n",
      "   - VRAM total disponible: 4.3GB\n",
      "   - Batch size actual: 2\n",
      "\n",
      "üìÖ --- √âpoca 1/10 ---\n",
      "‚úÖ Primer batch cargado y procesado.\n",
      "   [   1/3700] Loss: 0.9519 | Acc: 100.00% | ETA: 202224s | Preds: {'Robo': 2} | GPU: 0.5GB\n",
      "   [ 201/3700] Loss: 0.3899 | Acc: 61.69% | ETA: 11098s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [ 401/3700] Loss: 0.5272 | Acc: 67.96% | ETA: 10002s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [ 601/3700] Loss: 1.3740 | Acc: 74.04% | ETA: 9254s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [ 801/3700] Loss: 0.0957 | Acc: 78.46% | ETA: 8549s | Preds: {'Robo': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [1001/3700] Loss: 0.0043 | Acc: 81.87% | ETA: 7952s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [1201/3700] Loss: 0.0230 | Acc: 83.64% | ETA: 7329s | Preds: {'Robo': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [1401/3700] Loss: 0.0075 | Acc: 85.40% | ETA: 6762s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [1601/3700] Loss: 0.0072 | Acc: 86.82% | ETA: 6201s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [1801/3700] Loss: 0.0110 | Acc: 87.84% | ETA: 5616s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [2001/3700] Loss: 0.0052 | Acc: 88.93% | ETA: 5010s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [2201/3700] Loss: 0.0660 | Acc: 89.80% | ETA: 4404s | Preds: {'Robo': 2} | GPU: 0.5GB\n",
      "   [2401/3700] Loss: 0.0634 | Acc: 90.50% | ETA: 3818s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [2601/3700] Loss: 0.0608 | Acc: 91.00% | ETA: 3226s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [2801/3700] Loss: 0.0026 | Acc: 91.57% | ETA: 2628s | Preds: {'Robo': 2} | GPU: 0.5GB\n",
      "   [3001/3700] Loss: 0.0015 | Acc: 91.97% | ETA: 2032s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [3201/3700] Loss: 0.0011 | Acc: 92.27% | ETA: 1445s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [3401/3700] Loss: 0.0234 | Acc: 92.53% | ETA: 863s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [3601/3700] Loss: 0.0016 | Acc: 92.77% | ETA: 285s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [3700/3700] Loss: 0.0030 | Acc: 92.93% | ETA:   0s | Preds: {'Normal': 2} | GPU: 0.5GB\n",
      "   ‚úÖ √âpoca 1 completada en 10646s\n",
      "      Train Loss: 0.2105, Train Acc: 92.93%\n",
      "      Valid Loss: 1.3587, Valid Acc: 62.70%\n",
      "      LR actual: 1.00e-04\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Loss = 1.148\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Accuracy = 30.2%\n",
      "      ‚ö†Ô∏è Posible sobreajuste: Val Loss 1.359 >> Train Loss 0.210\n",
      "üíæ Checkpoint guardado: checkpoint_epoch_1.pth\n",
      "   ‚≠ê Nuevo mejor modelo guardado (Val Loss: 1.3587)\n",
      "      VRAM m√°xima usada: 2.0 GB\n",
      "\n",
      "üìÖ --- √âpoca 2/10 ---\n",
      "‚úÖ Primer batch cargado y procesado.\n",
      "   [   1/3700] Loss: 0.0022 | Acc: 100.00% | ETA: 9279s | Preds: {'Robo': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [ 201/3700] Loss: 0.0005 | Acc: 98.51% | ETA: 9340s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [ 401/3700] Loss: 0.0020 | Acc: 99.00% | ETA: 8944s | Preds: {'Robo': 2} | GPU: 0.5GB\n",
      "   [ 601/3700] Loss: 0.0022 | Acc: 99.25% | ETA: 8385s | Preds: {'Robo': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [ 801/3700] Loss: 0.0024 | Acc: 99.31% | ETA: 7870s | Preds: {'Normal': 2} | GPU: 0.5GB\n",
      "   [1001/3700] Loss: 0.0994 | Acc: 98.95% | ETA: 7339s | Preds: {'Robo': 2} | GPU: 0.5GB\n",
      "   [1201/3700] Loss: 0.0027 | Acc: 98.71% | ETA: 6799s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [1401/3700] Loss: 0.0938 | Acc: 98.61% | ETA: 6252s | Preds: {'Violencia': 2} | GPU: 0.5GB\n",
      "   [1601/3700] Loss: 0.0020 | Acc: 98.72% | ETA: 5692s | Preds: {'Robo': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [1801/3700] Loss: 0.0084 | Acc: 98.72% | ETA: 5155s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [2001/3700] Loss: 0.0201 | Acc: 98.65% | ETA: 4605s | Preds: {'Violencia': 2} | GPU: 0.5GB\n",
      "   [2201/3700] Loss: 0.0000 | Acc: 98.68% | ETA: 4059s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [2401/3700] Loss: 0.0022 | Acc: 98.71% | ETA: 3516s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [2601/3700] Loss: 0.0053 | Acc: 98.64% | ETA: 2969s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [2801/3700] Loss: 0.0011 | Acc: 98.64% | ETA: 2428s | Preds: {'Robo': 2} | GPU: 0.5GB\n",
      "   [3001/3700] Loss: 0.0003 | Acc: 98.70% | ETA: 1887s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [3201/3700] Loss: 0.0010 | Acc: 98.73% | ETA: 1346s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [3401/3700] Loss: 0.0007 | Acc: 98.81% | ETA: 806s | Preds: {'Robo': 2} | GPU: 0.5GB\n",
      "   [3601/3700] Loss: 0.0042 | Acc: 98.78% | ETA: 266s | Preds: {'Robo': 2} | GPU: 0.5GB\n",
      "   [3700/3700] Loss: 0.1558 | Acc: 98.77% | ETA:   0s | Preds: {'Robo': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   ‚úÖ √âpoca 2 completada en 9973s\n",
      "      Train Loss: 0.0479, Train Acc: 98.77%\n",
      "      Valid Loss: 1.6561, Valid Acc: 53.99%\n",
      "      LR actual: 1.00e-04\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Loss = 1.608\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Accuracy = 44.8%\n",
      "      ‚ö†Ô∏è Posible sobreajuste: Val Loss 1.656 >> Train Loss 0.048\n",
      "      ‚úÖ Progreso consistente: Loss baj√≥ 0.1626\n",
      "üíæ Checkpoint guardado: checkpoint_epoch_2.pth\n",
      "   üìâ Sin mejora por 1 √©pocas\n",
      "      VRAM m√°xima usada: 1.2 GB\n",
      "\n",
      "üìÖ --- √âpoca 3/10 ---\n",
      "‚úÖ Primer batch cargado y procesado.\n",
      "   [   1/3700] Loss: 0.0004 | Acc: 100.00% | ETA: 9739s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [ 201/3700] Loss: 0.0281 | Acc: 99.50% | ETA: 9291s | Preds: {'Robo': 2} | GPU: 0.5GB\n",
      "   [ 401/3700] Loss: 0.0008 | Acc: 99.25% | ETA: 8786s | Preds: {'Normal': 2} | GPU: 0.5GB\n",
      "   [ 601/3700] Loss: 0.0030 | Acc: 99.08% | ETA: 8275s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [ 801/3700] Loss: 0.0034 | Acc: 99.00% | ETA: 7766s | Preds: {'Robo': 2} | GPU: 0.5GB\n",
      "   [1001/3700] Loss: 0.0302 | Acc: 99.00% | ETA: 7233s | Preds: {'Violencia': 2} | GPU: 0.5GB\n",
      "   [1201/3700] Loss: 0.0006 | Acc: 99.00% | ETA: 6680s | Preds: {'Violencia': 2} | GPU: 0.5GB\n",
      "   [1401/3700] Loss: 0.5464 | Acc: 99.04% | ETA: 6186s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [1601/3700] Loss: 0.0072 | Acc: 98.97% | ETA: 5717s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [1801/3700] Loss: 0.0011 | Acc: 99.03% | ETA: 5200s | Preds: {'Robo': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [2001/3700] Loss: 0.0113 | Acc: 99.13% | ETA: 4686s | Preds: {'Normal': 2} | GPU: 0.5GB\n",
      "   [2201/3700] Loss: 0.0005 | Acc: 99.05% | ETA: 4152s | Preds: {'Normal': 2} | GPU: 0.5GB\n",
      "   [2401/3700] Loss: 0.0004 | Acc: 99.06% | ETA: 3609s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [2601/3700] Loss: 0.0001 | Acc: 99.04% | ETA: 3070s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [2801/3700] Loss: 0.0193 | Acc: 98.98% | ETA: 2520s | Preds: {'Robo': 2} | GPU: 0.5GB\n",
      "   [3001/3700] Loss: 0.0083 | Acc: 98.98% | ETA: 1964s | Preds: {'Violencia': 2} | GPU: 0.5GB\n",
      "   [3201/3700] Loss: 0.0001 | Acc: 98.98% | ETA: 1406s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [3401/3700] Loss: 0.0004 | Acc: 98.99% | ETA: 844s | Preds: {'Normal': 1, 'Robo': 1} | GPU: 0.5GB\n",
      "   [3601/3700] Loss: 0.0122 | Acc: 98.93% | ETA: 280s | Preds: {'Robo': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   [3700/3700] Loss: 0.0077 | Acc: 98.96% | ETA:   0s | Preds: {'Normal': 1, 'Violencia': 1} | GPU: 0.5GB\n",
      "   ‚úÖ √âpoca 3 completada en 10496s\n",
      "      Train Loss: 0.0380, Train Acc: 98.96%\n",
      "      Valid Loss: 1.6516, Valid Acc: 53.63%\n",
      "      LR actual: 1.00e-04\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Loss = 1.614\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Accuracy = 45.3%\n",
      "      ‚ö†Ô∏è Posible sobreajuste: Val Loss 1.652 >> Train Loss 0.038\n",
      "      ‚úÖ Progreso consistente: Loss baj√≥ 0.0099\n",
      "üíæ Checkpoint guardado: checkpoint_epoch_3.pth\n",
      "   üìâ Sin mejora por 2 √©pocas\n",
      "\n",
      "üõë Early stopping en la √©poca 3\n",
      "\n",
      "üíæ Mejor modelo guardado como 'i3d_finetuned_violencia_robo_normal.pth'\n",
      "\n",
      "‚ö†Ô∏è Error exportando m√©tricas a Excel: No module named 'openpyxl'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpyxl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:5\u001b[0m\n",
      "Cell \u001b[1;32mIn [20], line 80\u001b[0m, in \u001b[0;36mejecutar_entrenamiento\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ DataLoaders creados: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m batches de entrenamiento, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m batches de validaci√≥n\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Entrenar\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m \u001b[43mentrenar_modelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müéâ ¬°Entrenamiento completado!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtyspe \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[1;32mIn [19], line 204\u001b[0m, in \u001b[0;36mentrenar_modelo\u001b[1;34m(model, train_loader, val_loader, device, num_epochs, config)\u001b[0m\n\u001b[0;32m    202\u001b[0m exportar_metricas_excel(history, METRICS_FILE)\n\u001b[0;32m    203\u001b[0m df_metrics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(history)\n\u001b[1;32m--> 204\u001b[0m \u001b[43mdf_metrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMETRICS_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìä M√©tricas de entrenamiento guardadas en \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMETRICS_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nic_s\\anaconda3\\envs\\deepgpu\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nic_s\\anaconda3\\envs\\deepgpu\\lib\\site-packages\\pandas\\core\\generic.py:2436\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2423\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2425\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2426\u001b[0m     df,\n\u001b[0;32m   2427\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2434\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2435\u001b[0m )\n\u001b[1;32m-> 2436\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2438\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nic_s\\anaconda3\\envs\\deepgpu\\lib\\site-packages\\pandas\\io\\formats\\excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nic_s\\anaconda3\\envs\\deepgpu\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:57\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     46\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m WriteExcelBuffer \u001b[38;5;241m|\u001b[39m ExcelWriter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Use the openpyxl module as the Excel writer.\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m     engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     62\u001b[0m         path,\n\u001b[0;32m     63\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m     67\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "EARLY_STOPPING_PATIENCE = 2\n",
    "TRAIN_DIR = \"./tav_clean/training\"\n",
    "VALIDATION_DIR = \"./tav_clean/validacion\"\n",
    "OUTPUT_MODEL = \"i3d_finetuned_violencia_robo_normal.pth\"\n",
    "METRICS_FILE = \"training_metrics.xlsx\"\n",
    "ejecutar_entrenamiento()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec3dd3",
   "metadata": {},
   "source": [
    "# Segundo experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a176a935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creando modelo I3D-ResNet50 ‚Ä¶\n",
      "üîç Detectado formato PyTorchVideo (.pyth)\n",
      "‚úÖ Pesos preentrenados cargados: 320/320 capas\n",
      "‚úÖ Head: Dropout 0.3 + proyecci√≥n 3-clases\n",
      "üîÅ Checkpoint cargado. Missing=0, Unexpected=0\n",
      "\n",
      "üìÇ Buscando videos de ENTRENAMIENTO en: ./tav_clean/training\n",
      "‚úÖ Total de videos de entrenamiento: 274\n",
      "\n",
      "üìä [Resumen de videos por clase]\n",
      "   Normal: 115 videos\n",
      "   Robo: 83 videos\n",
      "   Violencia: 76 videos\n",
      "\n",
      "\n",
      "üìÇ Buscando videos de VALIDACI√ìN en: ./tav_clean/validacion\n",
      "‚úÖ Total de videos de validaci√≥n: 57\n",
      "\n",
      "üìä [Resumen de videos por clase]\n",
      "   Normal: 17 videos\n",
      "   Robo: 22 videos\n",
      "   Violencia: 18 videos\n",
      "\n",
      "\n",
      "üîÑ Creando datasets con sliding window...\n",
      "üìä Total de clips generados: 7401\n",
      "üìä Total de clips generados: 1103\n",
      "‚úÖ DataLoaders creados: 2467 batches de entrenamiento, 367 batches de validaci√≥n\n",
      "‚úÖ Mixed Precision habilitado (AMP)\n",
      "üöÄ Optimizaciones CUDA habilitadas (TF32, cuDNN benchmark)\n",
      "üìä VRAM disponible: 4.3 GB\n",
      "\n",
      "üöÄ [Entrenamiento iniciado en cuda:0]\n",
      "üìã Configuraci√≥n: 10 √©pocas, batch_size=3, lr=3e-05\n",
      "üí° TIPS para maximizar GPU:\n",
      "   - Si GPU < 2GB durante entrenamiento, considera aumentar batch_size\n",
      "   - VRAM total disponible: 4.3GB\n",
      "   - Batch size actual: 3\n",
      "\n",
      "üìÖ --- √âpoca 1/10 ---\n",
      "‚úÖ Primer batch cargado y procesado.\n",
      "   [   1/2467] Loss: 0.0062 | Acc: 100.00% | ETA: 208241s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 0.8GB / peak: 2.1GB\n",
      "   [ 201/2467] Loss: 0.0332 | Acc: 99.17% | ETA: 11873s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [ 401/2467] Loss: 0.0035 | Acc: 99.17% | ETA: 10249s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [ 601/2467] Loss: 0.0033 | Acc: 99.17% | ETA: 9062s | Preds: {'Normal': 1, 'Violencia': 2} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [ 801/2467] Loss: 0.0532 | Acc: 99.17% | ETA: 7911s | Preds: {'Robo': 3} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [1001/2467] Loss: 0.0084 | Acc: 99.20% | ETA: 6878s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [1201/2467] Loss: 0.0100 | Acc: 99.22% | ETA: 5940s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [1401/2467] Loss: 0.0004 | Acc: 99.14% | ETA: 5021s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [1601/2467] Loss: 0.0044 | Acc: 99.19% | ETA: 4113s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [1801/2467] Loss: 0.0002 | Acc: 99.15% | ETA: 3169s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [2001/2467] Loss: 0.0011 | Acc: 99.20% | ETA: 2211s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [2201/2467] Loss: 0.0013 | Acc: 99.23% | ETA: 1260s | Preds: {'Normal': 1, 'Violencia': 2} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [2401/2467] Loss: 0.0007 | Acc: 99.21% | ETA: 314s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [2467/2467] Loss: 0.0016 | Acc: 99.23% | ETA:   0s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 1.0GB / peak: 2.2GB\n",
      "\n",
      "üîç Validando al final de la √©poca 1...\n",
      "   ‚úÖ √âpoca 1 completada en 11748s\n",
      "      Train Loss: 0.0265, Train Acc: 99.23%\n",
      "      Valid Loss: 1.0736, Valid Acc: 68.39%\n",
      "      LR actual: 3.00e-05\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Loss = 1.047\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Accuracy = 30.8%\n",
      "      ‚ö†Ô∏è Posible sobreajuste: Val Loss 1.074 >> Train Loss 0.026\n",
      "üíæ Checkpoint N¬∞1 guardado en checkpoint_latest.pth\n",
      "   ‚≠ê Nuevo mejor modelo guardado (Val Loss: 1.0736)\n",
      "      VRAM m√°xima usada: 2.2 GB\n",
      "\n",
      "üìÖ --- √âpoca 2/10 ---\n",
      "‚úÖ Primer batch cargado y procesado.\n",
      "   [   1/2467] Loss: 0.0009 | Acc: 100.00% | ETA: 11638s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 1.0GB / peak: 2.1GB\n",
      "   [ 201/2467] Loss: 0.0020 | Acc: 99.83% | ETA: 10979s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [ 401/2467] Loss: 0.0003 | Acc: 99.92% | ETA: 10040s | Preds: {'Normal': 1, 'Violencia': 2} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [ 601/2467] Loss: 0.0003 | Acc: 99.67% | ETA: 9082s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [ 801/2467] Loss: 0.0005 | Acc: 99.71% | ETA: 8059s | Preds: {'Robo': 1, 'Violencia': 2} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [1001/2467] Loss: 0.0113 | Acc: 99.67% | ETA: 7056s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [1201/2467] Loss: 0.0004 | Acc: 99.64% | ETA: 6082s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [1401/2467] Loss: 0.0016 | Acc: 99.55% | ETA: 5108s | Preds: {'Violencia': 3} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [1601/2467] Loss: 0.0001 | Acc: 99.52% | ETA: 4151s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [1801/2467] Loss: 0.0026 | Acc: 99.48% | ETA: 3194s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [2001/2467] Loss: 0.0000 | Acc: 99.48% | ETA: 2232s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [2201/2467] Loss: 0.0027 | Acc: 99.53% | ETA: 1273s | Preds: {'Robo': 3} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [2401/2467] Loss: 0.0001 | Acc: 99.54% | ETA: 316s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 1.0GB / peak: 2.2GB\n",
      "   [2467/2467] Loss: 0.0014 | Acc: 99.54% | ETA:   0s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 1.0GB / peak: 2.2GB\n",
      "\n",
      "üîç Validando al final de la √©poca 2...\n",
      "   ‚úÖ √âpoca 2 completada en 11805s\n",
      "      Train Loss: 0.0143, Train Acc: 99.54%\n",
      "      Valid Loss: 1.5443, Valid Acc: 63.67%\n",
      "      LR actual: 3.00e-05\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Loss = 1.530\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Accuracy = 35.9%\n",
      "      ‚ö†Ô∏è Posible sobreajuste: Val Loss 1.544 >> Train Loss 0.014\n",
      "      ‚úÖ Progreso consistente: Loss baj√≥ 0.0122\n",
      "üíæ Checkpoint N¬∞2 guardado en checkpoint_latest.pth\n",
      "   üìâ Sin mejora por 1 √©pocas\n",
      "      VRAM m√°xima usada: 2.2 GB\n",
      "\n",
      "üìÖ --- √âpoca 3/10 ---\n",
      "‚úÖ Primer batch cargado y procesado.\n",
      "   [   1/2467] Loss: 0.0012 | Acc: 100.00% | ETA: 12655s | Preds: {'Normal': 1, 'Violencia': 2} | GPU: 1.0GB / peak: 2.1GB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:26\u001b[0m\n",
      "Cell \u001b[1;32mIn [20], line 64\u001b[0m, in \u001b[0;36mentrenar_modelo\u001b[1;34m(model, train_loader, val_loader, device, num_epochs, config)\u001b[0m\n\u001b[0;32m     60\u001b[0m epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìÖ --- √âpoca \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Primer batch cargado y procesado.\u001b[39m\u001b[38;5;124m\"\u001b[39m)            \n",
      "File \u001b[1;32mc:\\Users\\nic_s\\anaconda3\\envs\\deepgpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    739\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\nic_s\\anaconda3\\envs\\deepgpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\nic_s\\anaconda3\\envs\\deepgpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\nic_s\\anaconda3\\envs\\deepgpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn [15], line 59\u001b[0m, in \u001b[0;36mSlidingWindowVideoDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     56\u001b[0m clip_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclips[idx]\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Cargar frames del clip\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_video_clip\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvideo_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_frame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend_frame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Convertir a tensor y aplicar transformaciones\u001b[39;00m\n\u001b[0;32m     66\u001b[0m video_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_frames(frames)\n",
      "Cell \u001b[1;32mIn [15], line 88\u001b[0m, in \u001b[0;36mSlidingWindowVideoDataset._load_video_clip\u001b[1;34m(self, video_path, start_frame, end_frame)\u001b[0m\n\u001b[0;32m     85\u001b[0m frame_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(start_frame, end_frame\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_frames, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame_idx \u001b[38;5;129;01min\u001b[39;00m frame_indices:\n\u001b[1;32m---> 88\u001b[0m     \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_POS_FRAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 3e-5\n",
    "EARLY_STOPPING_PATIENCE = 2\n",
    "TRAIN_DIR = \"./tav_clean/training\"\n",
    "VALIDATION_DIR = \"./tav_clean/validacion\"\n",
    "OUTPUT_MODEL = \"i3d_finetuned_violencia_robo_normal.pth\"\n",
    "METRICS_FILE = \"training_metrics.xlsx\"\n",
    "\n",
    "ckpt = torch.load(\"checkpoint_epoch_1.pth\", map_location=\"cpu\")\n",
    "\n",
    "model = crear_modelo_i3d(num_clases=len(LABELS), freeze_backbone=False)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "missing, unexpected = model.load_state_dict(\n",
    "        ckpt[\"model_state_dict\"], strict=False)\n",
    "print(f\"üîÅ Checkpoint cargado. Missing={len(missing)}, Unexpected={len(unexpected)}\")\n",
    "\n",
    "for name, p in model.named_parameters():\n",
    "    p.requires_grad = any(name.startswith(f\"blocks.{i}\") for i in [3,4,5]) or \"head\" in name\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=LEARNING_RATE, weight_decay=1e-5\n",
    ")\n",
    "\n",
    "train_loader, val_loader = recolectar_datasets()\n",
    "\n",
    "entrenar_modelo(model, train_loader, val_loader, device, EPOCHS, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d5378",
   "metadata": {},
   "source": [
    "# Tercer experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db01ab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creando modelo I3D-ResNet50‚Ä¶\n",
      "üîç Detectado formato PyTorchVideo (.pyth)\n",
      "‚úÖ Pesos preentrenados cargados: 320/320 capas\n",
      "‚úÖ Head: Dropout 0.5  |  proyecci√≥n ‚Üí 3 clases\n",
      "üîÅ Checkpoint cargado. Missing=0, Unexpected=0\n",
      "üîÑ Congelando capas del modelo:\n",
      "Pesos por clase  : [0.95787024 0.91997564 1.1221542 ]\n",
      "Etiqueta 0 = Normal, 1 = Robo, 2 = Violencia\n",
      "\n",
      "üìÇ Buscando videos de ENTRENAMIENTO en: ./tav_clean/training\n",
      "‚úÖ Total de videos de entrenamiento: 274\n",
      "\n",
      "üìä [Resumen de videos por clase]\n",
      "   Normal: 115 videos\n",
      "   Robo: 83 videos\n",
      "   Violencia: 76 videos\n",
      "\n",
      "\n",
      "üìÇ Buscando videos de VALIDACI√ìN en: ./tav_clean/validacion\n",
      "‚úÖ Total de videos de validaci√≥n: 57\n",
      "\n",
      "üìä [Resumen de videos por clase]\n",
      "   Normal: 17 videos\n",
      "   Robo: 22 videos\n",
      "   Violencia: 18 videos\n",
      "\n",
      "\n",
      "üîÑ Creando datasets con sliding window...\n",
      "üìä Total de clips generados: 8617\n",
      "üìä Total de clips generados: 1280\n",
      "‚úÖ DataLoaders creados: 2872 batches de entrenamiento, 1280 batches de validaci√≥n\n",
      "‚úÖ Mixed Precision habilitado (AMP)\n",
      "üöÄ Optimizaciones CUDA habilitadas (TF32, cuDNN benchmark)\n",
      "üìä VRAM disponible: 4.3 GB\n",
      "\n",
      "üöÄ [Entrenamiento iniciado en cuda:0]\n",
      "üìã Configuraci√≥n: 10 √©pocas, batch_size=3, lr=1e-05\n",
      "üí° TIPS para maximizar GPU:\n",
      "   - Si GPU < 2GB durante entrenamiento, considera aumentar batch_size\n",
      "   - VRAM total disponible: 4.3GB\n",
      "   - Batch size actual: 3\n",
      "\n",
      "üìÖ --- √âpoca 1/10 ---\n",
      "‚úÖ Primer batch cargado y procesado.\n",
      "   [   1/2872] Loss: 0.0021 | Acc: 100.00% | ETA: 10837s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.3GB / peak: 0.8GB\n",
      "   [ 201/2872] Loss: 0.0008 | Acc: 98.84% | ETA: 10949s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [ 401/2872] Loss: 0.0073 | Acc: 99.00% | ETA: 10352s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [ 601/2872] Loss: 0.0036 | Acc: 99.06% | ETA: 9538s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [ 801/2872] Loss: 0.0022 | Acc: 99.04% | ETA: 8764s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1001/2872] Loss: 0.0023 | Acc: 98.97% | ETA: 7938s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1201/2872] Loss: 0.0024 | Acc: 99.03% | ETA: 7082s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1401/2872] Loss: 0.0035 | Acc: 99.02% | ETA: 6245s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1601/2872] Loss: 0.0045 | Acc: 99.10% | ETA: 5403s | Preds: {'Robo': 1, 'Violencia': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1801/2872] Loss: 0.0001 | Acc: 99.11% | ETA: 4528s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2001/2872] Loss: 0.0242 | Acc: 99.17% | ETA: 3664s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2201/2872] Loss: 0.0019 | Acc: 99.20% | ETA: 2813s | Preds: {'Normal': 1, 'Violencia': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2401/2872] Loss: 0.0014 | Acc: 99.22% | ETA: 1971s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2601/2872] Loss: 0.0015 | Acc: 99.22% | ETA: 1130s | Preds: {'Normal': 1, 'Violencia': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2801/2872] Loss: 0.0009 | Acc: 99.24% | ETA: 295s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2872/2872] Loss: 0.0003 | Acc: 99.26% | ETA:   0s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "\n",
      "üîç Validando al final de la √©poca 1...\n",
      "   ‚úÖ √âpoca 1 completada en 11949s\n",
      "      Train Loss: 0.0236, Train Acc: 99.26%\n",
      "      Valid Loss: 1.0853, Valid Acc: 68.75%\n",
      "      LR actual: 1.00e-05\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Loss = 1.062\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Accuracy = 30.5%\n",
      "      ‚ö†Ô∏è Posible sobreajuste: Val Loss 1.085 >> Train Loss 0.024\n",
      "üíæ Checkpoint N¬∞1 guardado en checkpoint_latest.pth\n",
      "   ‚≠ê Nuevo mejor modelo guardado (Val Loss: 1.0853)\n",
      "      VRAM m√°xima usada: 1.8 GB\n",
      "\n",
      "üìÖ --- √âpoca 2/10 ---\n",
      "‚úÖ Primer batch cargado y procesado.\n",
      "   [   1/2872] Loss: 0.0014 | Acc: 100.00% | ETA: 11618s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.5GB / peak: 1.0GB\n",
      "   [ 201/2872] Loss: 0.0005 | Acc: 99.50% | ETA: 10924s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [ 401/2872] Loss: 0.0087 | Acc: 99.75% | ETA: 10060s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [ 601/2872] Loss: 0.0002 | Acc: 99.45% | ETA: 9241s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [ 801/2872] Loss: 0.0003 | Acc: 99.33% | ETA: 8391s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1001/2872] Loss: 0.0003 | Acc: 99.27% | ETA: 7585s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1201/2872] Loss: 0.0010 | Acc: 99.36% | ETA: 6767s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1401/2872] Loss: 0.0015 | Acc: 99.38% | ETA: 5950s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1601/2872] Loss: 0.0003 | Acc: 99.40% | ETA: 5137s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1801/2872] Loss: 0.0007 | Acc: 99.41% | ETA: 4327s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2001/2872] Loss: 0.0036 | Acc: 99.40% | ETA: 3528s | Preds: {'Robo': 3} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2201/2872] Loss: 0.0047 | Acc: 99.42% | ETA: 2733s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2401/2872] Loss: 0.0001 | Acc: 99.47% | ETA: 1926s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2601/2872] Loss: 0.0729 | Acc: 99.49% | ETA: 1107s | Preds: {'Violencia': 3} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2801/2872] Loss: 0.0813 | Acc: 99.49% | ETA: 289s | Preds: {'Robo': 1, 'Violencia': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2872/2872] Loss: 0.0003 | Acc: 99.48% | ETA:   0s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "\n",
      "üîç Validando al final de la √©poca 2...\n",
      "   ‚úÖ √âpoca 2 completada en 11720s\n",
      "      Train Loss: 0.0137, Train Acc: 99.48%\n",
      "      Valid Loss: 1.2744, Valid Acc: 67.03%\n",
      "      LR actual: 1.00e-05\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Loss = 1.261\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Accuracy = 32.4%\n",
      "      ‚ö†Ô∏è Posible sobreajuste: Val Loss 1.274 >> Train Loss 0.014\n",
      "      ‚úÖ Progreso consistente: Loss baj√≥ 0.0099\n",
      "üíæ Checkpoint N¬∞2 guardado en checkpoint_latest.pth\n",
      "   üìâ Sin mejora por 1 √©pocas\n",
      "      VRAM m√°xima usada: 1.1 GB\n",
      "\n",
      "üìÖ --- √âpoca 3/10 ---\n",
      "‚úÖ Primer batch cargado y procesado.\n",
      "   [   1/2872] Loss: 0.0023 | Acc: 100.00% | ETA: 11969s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.0GB\n",
      "   [ 201/2872] Loss: 0.0009 | Acc: 99.50% | ETA: 10540s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [ 401/2872] Loss: 0.0003 | Acc: 99.58% | ETA: 9895s | Preds: {'Normal': 1, 'Violencia': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [ 601/2872] Loss: 0.0004 | Acc: 99.45% | ETA: 9092s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [ 801/2872] Loss: 0.0083 | Acc: 99.46% | ETA: 8302s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1001/2872] Loss: 0.0005 | Acc: 99.57% | ETA: 7507s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1201/2872] Loss: 0.0017 | Acc: 99.58% | ETA: 6698s | Preds: {'Robo': 1, 'Violencia': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1401/2872] Loss: 0.0001 | Acc: 99.60% | ETA: 5912s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1601/2872] Loss: 0.0003 | Acc: 99.58% | ETA: 5122s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1801/2872] Loss: 0.0017 | Acc: 99.61% | ETA: 4322s | Preds: {'Robo': 3} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2001/2872] Loss: 0.0005 | Acc: 99.60% | ETA: 3519s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2201/2872] Loss: 0.0001 | Acc: 99.55% | ETA: 2709s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2401/2872] Loss: 0.0007 | Acc: 99.53% | ETA: 1913s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2601/2872] Loss: 0.0001 | Acc: 99.54% | ETA: 1104s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2801/2872] Loss: 0.0006 | Acc: 99.55% | ETA: 289s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2872/2872] Loss: 0.0028 | Acc: 99.56% | ETA:   0s | Preds: {'Normal': 3} | GPU: 0.5GB / peak: 1.1GB\n",
      "\n",
      "üîç Validando al final de la √©poca 3...\n",
      "   ‚úÖ √âpoca 3 completada en 11708s\n",
      "      Train Loss: 0.0121, Train Acc: 99.56%\n",
      "      Valid Loss: 1.2074, Valid Acc: 65.47%\n",
      "      LR actual: 1.00e-05\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Loss = 1.195\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Accuracy = 34.1%\n",
      "      ‚ö†Ô∏è Posible sobreajuste: Val Loss 1.207 >> Train Loss 0.012\n",
      "      ‚úÖ Progreso consistente: Loss baj√≥ 0.0016\n",
      "üíæ Checkpoint N¬∞3 guardado en checkpoint_latest.pth\n",
      "   üìâ Sin mejora por 2 √©pocas\n",
      "      VRAM m√°xima usada: 1.1 GB\n",
      "\n",
      "üìÖ --- √âpoca 4/10 ---\n",
      "‚úÖ Primer batch cargado y procesado.\n",
      "   [   1/2872] Loss: 0.0001 | Acc: 100.00% | ETA: 11486s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.5GB / peak: 1.0GB\n",
      "   [ 201/2872] Loss: 0.0021 | Acc: 99.50% | ETA: 10791s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [ 401/2872] Loss: 0.0004 | Acc: 99.50% | ETA: 9860s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [ 601/2872] Loss: 0.0004 | Acc: 99.61% | ETA: 9087s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [ 801/2872] Loss: 0.0007 | Acc: 99.67% | ETA: 8274s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1001/2872] Loss: 0.0010 | Acc: 99.70% | ETA: 7469s | Preds: {'Violencia': 3} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1201/2872] Loss: 0.0304 | Acc: 99.69% | ETA: 6678s | Preds: {'Normal': 1, 'Violencia': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1401/2872] Loss: 0.0007 | Acc: 99.71% | ETA: 5882s | Preds: {'Robo': 1, 'Violencia': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1601/2872] Loss: 0.0012 | Acc: 99.75% | ETA: 5082s | Preds: {'Robo': 1, 'Violencia': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [1801/2872] Loss: 0.0009 | Acc: 99.76% | ETA: 4278s | Preds: {'Normal': 3} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2001/2872] Loss: 0.0007 | Acc: 99.75% | ETA: 3505s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2201/2872] Loss: 0.0001 | Acc: 99.70% | ETA: 2718s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2401/2872] Loss: 0.0001 | Acc: 99.71% | ETA: 1916s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2601/2872] Loss: 0.0002 | Acc: 99.68% | ETA: 1107s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2801/2872] Loss: 0.0005 | Acc: 99.64% | ETA: 290s | Preds: {'Normal': 1, 'Violencia': 2} | GPU: 0.5GB / peak: 1.1GB\n",
      "   [2872/2872] Loss: 0.0070 | Acc: 99.64% | ETA:   0s | Preds: {'Violencia': 3} | GPU: 0.5GB / peak: 1.1GB\n",
      "\n",
      "üîç Validando al final de la √©poca 4...\n",
      "   ‚úÖ √âpoca 4 completada en 11776s\n",
      "      Train Loss: 0.0114, Train Acc: 99.64%\n",
      "      Valid Loss: 1.4329, Valid Acc: 65.86%\n",
      "      LR actual: 3.00e-06\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Loss = 1.422\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Accuracy = 33.8%\n",
      "      ‚ö†Ô∏è Posible sobreajuste: Val Loss 1.433 >> Train Loss 0.011\n",
      "      ‚úÖ Progreso consistente: Loss baj√≥ 0.0007\n",
      "üíæ Checkpoint N¬∞4 guardado en checkpoint_latest.pth\n",
      "   üìâ Sin mejora por 3 √©pocas\n",
      "\n",
      "üõë Early stopping en la √©poca 4\n",
      "\n",
      "üíæ Mejor modelo guardado como 'i3d_finetuned_violencia_robo_normal.pth'\n",
      "CPU times: total: 2d 2h 35min 59s\n",
      "Wall time: 14h 43min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-5\n",
    "EARLY_STOPPING_PATIENCE = 3\n",
    "STRIDE = 1.8\n",
    "TRAIN_DIR = \"./tav_clean/training\"\n",
    "VALIDATION_DIR = \"./tav_clean/validacion\"\n",
    "OUTPUT_MODEL = \"i3d_finetuned_violencia_robo_normal.pth\"\n",
    "METRICS_FILE = \"training_metrics_clean.csv\"\n",
    "\n",
    "ckpt = torch.load(\"checkpoint_epoch_1.pth\", map_location=\"cpu\")\n",
    "\n",
    "model = crear_modelo_i3d(\n",
    "    dropout_p     = 0.5,\n",
    "    freeze_backbone = False,\n",
    "    pretrain_path = \"I3D_8x8_R50_pytorchvideo.pyth\",\n",
    "    num_clases    = 3\n",
    ")\n",
    "\n",
    "missing, unexpected = model.load_state_dict(ckpt[\"model_state_dict\"], strict=False)\n",
    "print(f\"üîÅ Checkpoint cargado. Missing={len(missing)}, Unexpected={len(unexpected)}\")\n",
    "\n",
    "print(f\"üîÑ Congelando capas del modelo:\")\n",
    "for name, p in model.named_parameters():\n",
    "    p.requires_grad = any(name.startswith(f\"blocks.{i}\") for i in [4,5]) or \"head\" in name\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=LEARNING_RATE, weight_decay=1e-5\n",
    ")\n",
    "# Basado en la cantidad de frames por clase, calcular pesos para CrossEntropyLoss\n",
    "cls_counts = np.array([165498, 172315, 141269], dtype=np.float32)\n",
    "\n",
    "class_weights = 1.0 / cls_counts\n",
    "class_weights = class_weights / class_weights.sum() * len(cls_counts)  \n",
    "\n",
    "class_weights_t = torch.tensor(class_weights, dtype=torch.float32)\n",
    "print(\"Pesos por clase  :\", class_weights)  \n",
    "print(\"Etiqueta 0 = Normal, 1 = Robo, 2 = Violencia\")\n",
    "\n",
    "train_loader, val_loader = recolectar_datasets()\n",
    "entrenar_modelo(model, train_loader, val_loader, device, EPOCHS, config, class_weights_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fe101d",
   "metadata": {},
   "source": [
    "# Cuarto experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8140897b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creando modelo I3D-ResNet50‚Ä¶\n",
      "‚úÖ Head: Dropout 0.6  |  proyecci√≥n ‚Üí 3 clases\n",
      "üîí Frozen: 10,168,131  |  üîì Trainable: 17,061,888\n",
      "Pesos por clase: [0.95787024 0.91997564 1.1221542 ]\n",
      "Etiqueta 0 = Normal, 1 = Robo, 2 = Violencia\n",
      "\n",
      "üìÇ Buscando videos de ENTRENAMIENTO en: ./tav_clean/training\n",
      "‚úÖ Total de videos de entrenamiento: 274\n",
      "\n",
      "üìä [Resumen de videos por clase]\n",
      "   Normal: 115 videos\n",
      "   Robo: 83 videos\n",
      "   Violencia: 76 videos\n",
      "\n",
      "\n",
      "üìÇ Buscando videos de VALIDACI√ìN en: ./tav_clean/validacion\n",
      "‚úÖ Total de videos de validaci√≥n: 57\n",
      "\n",
      "üìä [Resumen de videos por clase]\n",
      "   Normal: 17 videos\n",
      "   Robo: 22 videos\n",
      "   Violencia: 18 videos\n",
      "\n",
      "\n",
      "üîÑ Creando datasets con sliding window...\n",
      "üìä Total de clips generados: 8617\n",
      "üìä Total de clips generados: 1280\n",
      "‚úÖ DataLoaders creados: 2872 batches de entrenamiento, 1280 batches de validaci√≥n\n",
      "‚úÖ Mixed Precision habilitado (AMP)\n",
      "üöÄ Optimizaciones CUDA habilitadas (TF32, cuDNN benchmark)\n",
      "üìä VRAM disponible: 4.3 GB\n",
      "\n",
      "üöÄ [Entrenamiento iniciado en cuda:0]\n",
      "üìã Configuraci√≥n: 10 √©pocas, batch_size=3, lr=5e-06\n",
      "üí° TIPS para maximizar GPU:\n",
      "   - Si GPU < 2GB durante entrenamiento, considera aumentar batch_size\n",
      "   - VRAM total disponible: 4.3GB\n",
      "   - Batch size actual: 3\n",
      "\n",
      "üìÖ --- √âpoca 1/10 ---\n",
      "‚úÖ Primer batch cargado y procesado.\n",
      "   [   1/2872] Loss: 0.7416 | Acc: 100.00% | ETA: 9405s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.6GB / peak: 1.1GB\n",
      "   [ 201/2872] Loss: 0.5545 | Acc: 99.83% | ETA: 9923s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [ 401/2872] Loss: 0.4292 | Acc: 99.75% | ETA: 9208s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [ 601/2872] Loss: 0.2958 | Acc: 99.72% | ETA: 8449s | Preds: {'Robo': 1, 'Violencia': 2} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [ 801/2872] Loss: 0.3340 | Acc: 99.71% | ETA: 7805s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [1001/2872] Loss: 0.3196 | Acc: 99.70% | ETA: 7090s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [1201/2872] Loss: 0.3216 | Acc: 99.72% | ETA: 6367s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [1401/2872] Loss: 0.2986 | Acc: 99.71% | ETA: 5679s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [1601/2872] Loss: 0.3547 | Acc: 99.73% | ETA: 4939s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [1801/2872] Loss: 0.3518 | Acc: 99.69% | ETA: 4155s | Preds: {'Robo': 3} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [2001/2872] Loss: 0.3034 | Acc: 99.68% | ETA: 3373s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [2201/2872] Loss: 0.3307 | Acc: 99.71% | ETA: 2586s | Preds: {'Robo': 3} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [2401/2872] Loss: 0.4274 | Acc: 99.69% | ETA: 1808s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [2601/2872] Loss: 0.3313 | Acc: 99.71% | ETA: 1036s | Preds: {'Normal': 3} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [2801/2872] Loss: 0.3452 | Acc: 99.70% | ETA: 270s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [2872/2872] Loss: 0.3242 | Acc: 99.71% | ETA:   0s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "\n",
      "üîç Validando al final de la √©poca 1...\n",
      "   ‚úÖ √âpoca 1 completada en 10952s\n",
      "      Train Loss: 0.3552, Train Acc: 99.71%\n",
      "      Valid Loss: 0.9205, Valid Acc: 66.09%\n",
      "      LR actual: 5.00e-06\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Loss = 0.565\n",
      "      ‚ö†Ô∏è SOBREAJUSTE DETECTADO: Gap Accuracy = 33.6%\n",
      "      ‚ö†Ô∏è Posible sobreajuste: Val Loss 0.921 >> Train Loss 0.355\n",
      "üíæ Checkpoint N¬∞1 guardado en checkpoint_latest.pth\n",
      "   ‚≠ê Nuevo mejor modelo guardado (Val Loss: 0.9205)\n",
      "      VRAM m√°xima usada: 1.3 GB\n",
      "\n",
      "üìÖ --- √âpoca 2/10 ---\n",
      "‚úÖ Primer batch cargado y procesado.\n",
      "   [   1/2872] Loss: 0.3029 | Acc: 100.00% | ETA: 10920s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.7GB / peak: 1.2GB\n",
      "   [ 201/2872] Loss: 0.3284 | Acc: 100.00% | ETA: 9997s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [ 401/2872] Loss: 0.2742 | Acc: 99.83% | ETA: 9348s | Preds: {'Normal': 1, 'Violencia': 2} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [ 601/2872] Loss: 0.3176 | Acc: 99.78% | ETA: 8706s | Preds: {'Normal': 2, 'Robo': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [ 801/2872] Loss: 0.3119 | Acc: 99.79% | ETA: 7984s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [1001/2872] Loss: 0.2759 | Acc: 99.73% | ETA: 7189s | Preds: {'Normal': 1, 'Violencia': 2} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [1201/2872] Loss: 0.3109 | Acc: 99.78% | ETA: 6430s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [1401/2872] Loss: 0.3003 | Acc: 99.81% | ETA: 5653s | Preds: {'Robo': 2, 'Violencia': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [1601/2872] Loss: 0.3128 | Acc: 99.77% | ETA: 4898s | Preds: {'Normal': 3} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [1801/2872] Loss: 0.2940 | Acc: 99.72% | ETA: 4132s | Preds: {'Normal': 2, 'Violencia': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [2001/2872] Loss: 0.2956 | Acc: 99.70% | ETA: 3376s | Preds: {'Normal': 1, 'Robo': 1, 'Violencia': 1} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [2201/2872] Loss: 0.3284 | Acc: 99.71% | ETA: 2610s | Preds: {'Normal': 1, 'Robo': 2} | GPU: 0.7GB / peak: 1.3GB\n",
      "   [2401/2872] Loss: 0.2819 | Acc: 99.74% | ETA: 1846s | Preds: {'Robo': 1, 'Violencia': 2} | GPU: 0.7GB / peak: 1.3GB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 5e-6\n",
    "EARLY_STOPPING_PATIENCE = 3\n",
    "STRIDE = 1.8\n",
    "LABEL_SMOOTH = 0.10 \n",
    "TRAIN_DIR = \"./tav_clean/training\"\n",
    "VALIDATION_DIR = \"./tav_clean/validacion\"\n",
    "OUTPUT_MODEL = \"i3d_finetuned_violencia_robo_normal.pth\"\n",
    "METRICS_FILE = \"training_metrics_clean.csv\"\n",
    "\n",
    "best_weights = torch.load(\"i3d_finetuned_violencia_robo_normal.pth\", map_location=\"cpu\")\n",
    "\n",
    "model = crear_modelo_i3d(\n",
    "        dropout_p=0.6,\n",
    "        freeze_backbone=False,\n",
    "        pretrain_path=None,\n",
    "        num_clases=3\n",
    ")\n",
    "model.load_state_dict(best_weights)\n",
    "\n",
    "# Congelar bloques 0-4 y entrenar s√≥lo blocks.5 + head\n",
    "for n, p in model.named_parameters():\n",
    "    p.requires_grad = n.startswith(\"blocks.5\") or \"head\" in n\n",
    "\n",
    "frozen    = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"üîí Frozen: {frozen:,}  |  üîì Trainable: {trainable:,}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "cls_counts = torch.tensor([165498, 172315, 141269], dtype=torch.float32)\n",
    "class_weights = (1. / cls_counts)\n",
    "class_weights = class_weights / class_weights.sum() * len(cls_counts)\n",
    "print(\"Pesos por clase:\", class_weights.numpy())   \n",
    "print(\"Etiqueta 0 = Normal, 1 = Robo, 2 = Violencia\")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.3, patience=2\n",
    ")\n",
    "\n",
    "train_loader, val_loader = recolectar_datasets()\n",
    "\n",
    "entrenar_modelo(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    EPOCHS,\n",
    "    config,\n",
    "    class_weights.to(device)  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb43048",
   "metadata": {},
   "source": [
    "# Evaluaci√≥n sobre test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ca008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns; import matplotlib.pyplot as plt\n",
    "\n",
    "LABELS        = [\"Normal\", \"Robo\", \"Violencia\"]\n",
    "CLIP_DURATION = 2.56       \n",
    "NUM_FRAMES    = 32\n",
    "STRIDE        = 1.0\n",
    "BATCH_SIZE    = 3\n",
    "DEVICE        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# MODELOS\n",
    "MODELS = {\n",
    "    \"exp1_clean\"  : (\"best_i3d_exp1.pth\", 0.30, (0,1,2,3,4)),\n",
    "    \"exp3_clean\"  : (\"best_i3d_exp3.pth\", 0.50, (0,1,2,3)),\n",
    "    \"exp4_clean\"  : (\"best_i3d_exp4.pth\", 0.60, (0,1,2,3,4)),\n",
    "    \"exp_raw\"     : (\"i3d_finetuned_violencia_robo_normal.pth\",  None, (0,1,2,3,4,5))  # sin dropout\n",
    "}\n",
    "\n",
    "# DATASET DE TEST\n",
    "TEST_DIR = Path(\"./tav_clean/test\")\n",
    "test_paths = [p for p in TEST_DIR.rglob(\"*.mp4\")]\n",
    "print(f\"üóÇÔ∏è  Videos de test: {len(test_paths)}\")\n",
    "\n",
    "test_dataset = SlidingWindowVideoDataset(\n",
    "    video_paths=test_paths,\n",
    "    clip_duration=CLIP_DURATION,\n",
    "    stride=STRIDE,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    transform=VAL_TRANSFORM            \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "# EVALUACI√ìN DE MODELOS\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"infer\", leave=False):\n",
    "            x  = batch[\"video\"].to(DEVICE, non_blocking=True)\n",
    "            yt = batch[\"label\"].to(DEVICE, non_blocking=True)\n",
    "\n",
    "            yp = model(x).argmax(1)\n",
    "            y_true.append(yt.cpu())\n",
    "            y_pred.append(yp.cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true).numpy()\n",
    "    y_pred = torch.cat(y_pred).numpy()\n",
    "\n",
    "    rep = classification_report(\n",
    "        y_true, y_pred, target_names=LABELS, digits=4, output_dict=True)\n",
    "    cm  = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return rep, cm\n",
    "\n",
    "results = {}\n",
    "for nickname, (ckpt_path, dp, freeze_set) in MODELS.items():\n",
    "    print(f\"\\nüîç Evaluando {nickname}\")\n",
    "    model = crear_modelo_i3d(\n",
    "                dropout_p=dp,      \n",
    "                freeze_backbone=False,\n",
    "                pretrain_path=None,\n",
    "                num_clases=3)\n",
    "    state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(state, strict=True)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    rep, cm = evaluate(model, test_loader)\n",
    "    results[nickname] = {\"rep\": rep, \"cm\": cm}\n",
    "\n",
    "# Resumen de resultados\n",
    "rows = []\n",
    "for name, out in results.items():\n",
    "    rows.append([\n",
    "        name,\n",
    "        out[\"rep\"][\"accuracy\"],\n",
    "        out[\"rep\"][\"Violencia\"][\"f1-score\"],\n",
    "        out[\"rep\"][\"Robo\"][\"f1-score\"],\n",
    "        out[\"rep\"][\"Normal\"][\"f1-score\"]\n",
    "    ])\n",
    "df = pd.DataFrame(rows, columns=[\"Modelo\",\"Acc\",\"F1-Viol\",\"F1-Robo\",\"F1-Norm\"])\n",
    "print(df.sort_values(\"Acc\", ascending=False).to_string(index=False))\n",
    "\n",
    "# Matrices de confusi√≥n\n",
    "for name, out in results.items():\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(out[\"cm\"], annot=True, fmt=\"d\",\n",
    "                xticklabels=LABELS, yticklabels=LABELS, cmap=\"Blues\")\n",
    "    plt.title(f\"Confusi√≥n ‚Äì {name}\")\n",
    "    plt.xlabel(\"Predicci√≥n\"); plt.ylabel(\"Real\")\n",
    "    plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
